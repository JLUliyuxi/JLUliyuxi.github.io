<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="药学 自由人 爱好者"><meta name="keywords" content=""><meta name="author" content="LyC"><meta name="copyright" content="LyC"><title>莫道君行早 更有早行人 | LyC's Blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="LyC's Blog" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="https://i.loli.net/2020/05/17/HbaOsFvjp8c9MRE.jpg"></div><div class="author-info__name text-center">LyC</div><div class="author-info__description text-center">药学 自由人 爱好者</div><div class="follow-button"><a href="https://jluliyuxi.github.io/">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">17</span></a></div></div></div><nav id="nav" style="background-image: url(https://i.loli.net/2020/05/12/jFsUgX9TBbnQu2o.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">LyC's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="site-info"><div id="site-title">LyC's Blog</div><div id="site-sub-title">莫道君行早 更有早行人</div><div id="site-social-icons"><a class="social-icon" href="https://github.com/JLUliyuxi || github" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-github fa"></i></a><a class="social-icon" href="https://weibo.com/3687299900/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo || weibo" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-weibo fa"></i></a><a class="social-icon" href="https://www.google.com || chrome" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-chrome fa"></i></a></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/16/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%EF%BC%88%E7%AC%AC2%E5%91%A8%20%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E6%8F%90%E5%8F%96%20%E5%8D%95%E5%85%83%E4%BA%94%20%E4%BF%A1%E6%81%AF%E7%BB%84%E7%BB%87%E4%B8%8E%E6%8F%90%E5%8F%96%E6%96%B9%E6%B3%95%EF%BC%89/">Python网络爬虫与信息提取（第2周 网络爬虫提取 单元五 信息组织与提取方法）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-16</time><div class="content"><h1 id="信息标记的三种形式"><a href="#信息标记的三种形式" class="headerlink" title="信息标记的三种形式"></a>信息标记的三种形式</h1><h2 id="XML（eXtensible-Markup-Language）"><a href="#XML（eXtensible-Markup-Language）" class="headerlink" title="XML（eXtensible Markup Language）"></a>XML（eXtensible Markup Language）</h2><p>标签中含有内容时：<code>&lt;name&gt; ... &lt;/name&gt;</code>  </p>
<p>标签中不含内容时：<code>&lt;name/&gt;</code>     </p>
<p>注释：<code>&lt;!-- --&gt;</code></p>
<h2 id="JSON-JavaScript-Object-Notation"><a href="#JSON-JavaScript-Object-Notation" class="headerlink" title="JSON(JavaScript Object Notation)"></a>JSON(JavaScript Object Notation)</h2><p>“key” : “value”<br>“key” : [“value1”,”value2”]<br>“key” : {“subkey”:”subvalue”}<br>“key” : {<br>&ensp;&ensp;”name1” : “value1”<br>&ensp;&ensp;”name2” : “value2”<br>}   </p>
<h2 id="YAML"><a href="#YAML" class="headerlink" title="YAML"></a>YAML</h2><p><strong>无类型键值对</strong> key:name     </p>
<p><strong>通过缩进表达所属关系</strong>：<br>name :<br>&ensp;&ensp;newname :<br>&ensp;&ensp;oldname :     </p>
<p><strong>用-号表达并列关系</strong>：<br>name :<br>-name1<br>-name2      </p>
<p><strong>用|表示整块数据 #表示注释</strong>      </p>
<h1 id="三种信息标记形式的比较"><a href="#三种信息标记形式的比较" class="headerlink" title="三种信息标记形式的比较"></a>三种信息标记形式的比较</h1><p>XML Internet.上的信息交互与传递。<br>JSON 移动应用云端和节点的信息通信，无注释。<br>YAML 各类系统的配置文件，有注释易读。       </p>
<h1 id="信息提取的一般方法"><a href="#信息提取的一般方法" class="headerlink" title="信息提取的一般方法"></a>信息提取的一般方法</h1><h2 id="方法一-完整解析信息的标记形式，再提取关键信息。"><a href="#方法一-完整解析信息的标记形式，再提取关键信息。" class="headerlink" title="方法一:完整解析信息的标记形式，再提取关键信息。"></a>方法一:完整解析信息的标记形式，再提取关键信息。</h2><p>XML JSON YAML<br><strong>需要标记解析器</strong><br>例如: bs4库的标签树遍历<br>优点:信息解析准确<br>缺点:提取过程繁琐，速度慢。      </p>
<h2 id="方法二-无视标记形式，直接搜索关键信息。"><a href="#方法二-无视标记形式，直接搜索关键信息。" class="headerlink" title="方法二:无视标记形式，直接搜索关键信息。"></a>方法二:无视标记形式，直接搜索关键信息。</h2><p><strong>搜索</strong><br>对信息的文本查找函数即可。<br>优点:提取过程简洁，速度较快。<br>缺点:提取结果准确性与信息内容相关。      </p>
<h1 id="基于bs4库的HTML内容查找方法"><a href="#基于bs4库的HTML内容查找方法" class="headerlink" title="基于bs4库的HTML内容查找方法"></a>基于bs4库的HTML内容查找方法</h1><p><strong>&lt; &gt;.find_ all(name, attrs, recursive, string, **kwargs)</strong><br>返回一个列表类型，存储查找的结果。<br><strong>name</strong>:对标签名称的检索字符串。<br><strong>attrs</strong>:对标签属性值的检索字符串，可标注属性检索。<br><strong>recursive</strong>:是否对子孙全部检索，默认True。<br><strong>string: &lt; &gt;… &lt; / &gt;</strong>:中字符串区域的检索字符串。      </p>
<p><strong>扩展方法</strong></p>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">&lt;&gt;.find()</td>
<td align="center">搜索且只返回一个结果，字符串类型，同.find_all()参数</td>
</tr>
<tr>
<td align="center">&lt;&gt;.find_parents()</td>
<td align="center">在先辈节点中搜索，返回列表类型，同.find_all()参数</td>
</tr>
<tr>
<td align="center">&lt;&gt;.find_parent()</td>
<td align="center">在先辈节点中返回一个结果，字符串类型，同.find()参数</td>
</tr>
<tr>
<td align="center">&lt;&gt;.find_next_siblings()</td>
<td align="center">在后续平行节点中搜索，返回列表类型，同.find_all()参数</td>
</tr>
<tr>
<td align="center">&lt;&gt;.find_ next sibling()</td>
<td align="center">在后续平行节点中返回一个结果，字符串类型,同.find()参数</td>
</tr>
<tr>
<td align="center">&lt;&gt;.find_previous_siblings()</td>
<td align="center">在前序平行节点中搜索，返回列表类型，同.find_all()参数</td>
</tr>
<tr>
<td align="center">&lt;&gt;.find_previous_sibling()</td>
<td align="center">在前序平行节点中返回一个结果，字符串类型，同.find()参数</td>
</tr>
</tbody></table>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/11/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%EF%BC%88%E7%AC%AC2%E5%91%A8%20%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E6%8F%90%E5%8F%96%20%E5%8D%95%E5%85%83%E5%9B%9B%20BeautifulSoup%E5%BA%93%E5%85%A5%E9%97%A8%EF%BC%89/">Python网络爬虫与信息提取（第2周 网络爬虫提取 单元四 BeautifulSoup库入门）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-11</time><div class="content"><h1 id="BeautifulSoup库的安装"><a href="#BeautifulSoup库的安装" class="headerlink" title="BeautifulSoup库的安装"></a>BeautifulSoup库的安装</h1><p>命令行内输入<code>pip install beautifulsoup4</code>      </p>
<h1 id="BeautifulSoup库的测试"><a href="#BeautifulSoup库的测试" class="headerlink" title="BeautifulSoup库的测试"></a>BeautifulSoup库的测试</h1><p>在任一浏览器中输入<code>http://python123.io/ws/demo.html</code><br>查看网站的源代码    </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;python123.io&#x2F;ws&#x2F;demo.html&#39;)</span><br><span class="line">demo &#x3D; r.text #获取网站的源代码</span><br><span class="line">soup &#x3D; BeautifulSoup(demo, &#39;html.parser&#39;) #对demo进行html的解析</span><br><span class="line">print(soup.prettify())</span><br></pre></td></tr></table></figure>
<p><strong>主要用法</strong>    </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">soup &#x3D; BeautifulSoup(&#39;&lt;p&gt;data&lt;&#x2F;p&gt;&#39;,&#39;html.parser&#39;)</span><br></pre></td></tr></table></figure>
<h1 id="BeautifulSoup库的基本元素"><a href="#BeautifulSoup库的基本元素" class="headerlink" title="BeautifulSoup库的基本元素"></a>BeautifulSoup库的基本元素</h1><p><img src="https://i.loli.net/2020/06/11/cuA1DqJTfeilpkj.png" alt=""></p>
<p>属性是由键值对构成的<br><strong>BeautifulSoup库解析器</strong></p>
<table>
<thead>
<tr>
<th align="center">解析器</th>
<th align="center">使用方法</th>
<th align="center">条件</th>
</tr>
</thead>
<tbody><tr>
<td align="center">bs4的HTML解析器</td>
<td align="center">BeautifulSoup(mk,’html.parser)</td>
<td align="center">安装bs4库</td>
</tr>
<tr>
<td align="center">lxml的HTML解析器</td>
<td align="center">BeautifulSoup(mk,’lxml’)</td>
<td align="center">pip install lxml</td>
</tr>
<tr>
<td align="center">lxml的XML解析器</td>
<td align="center">BeautifulSoup(mk,’ xml’)</td>
<td align="center">pip install lxml</td>
</tr>
<tr>
<td align="center">html5lib的解析器</td>
<td align="center">BeautifulSoup( mk,’ html5lib’)</td>
<td align="center">pip install html5lib</td>
</tr>
</tbody></table>
<p><strong>BeautifulSoup类的基本元素</strong></p>
<table>
<thead>
<tr>
<th align="center">基本元素</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Tag</td>
<td align="center">标签，最基本的信息组织单元，分别用&lt;&gt;和&lt;/&gt;标明开头和结尾</td>
</tr>
<tr>
<td align="center">Name</td>
<td align="center">标签的名字，&lt; p &gt;…&lt; /p &gt;的名字是’p’， 格式: &lt; tag &gt;.name</td>
</tr>
<tr>
<td align="center">Attributes</td>
<td align="center">标签的属性，字典形式组织，格式: &lt; tag &gt; .attrs</td>
</tr>
<tr>
<td align="center">NavigableString</td>
<td align="center">标签内非属性字符串，&lt;&gt;…&lt;/&gt;中字符串， 格式: &lt; tag     &gt;.string</td>
</tr>
<tr>
<td align="center">Comment</td>
<td align="center">标签内字符串的注释部分，一种特殊的Comment类型</td>
</tr>
</tbody></table>
<p><strong>获取Tag的方法</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;python123.io&#x2F;ws&#x2F;demo.html&#39;)</span><br><span class="line">demo &#x3D; r.text #获取网站的源代码</span><br><span class="line">soup &#x3D; BeautifulSoup(demo, &#39;html.parser&#39;)</span><br><span class="line">print(soup.title)</span><br><span class="line">tag &#x3D; soup.a</span><br><span class="line">print(tag)</span><br></pre></td></tr></table></figure>
<p><strong>获取Name的方法</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;python123.io&#x2F;ws&#x2F;demo.html&#39;)</span><br><span class="line">demo &#x3D; r.text #获取网站的源代码</span><br><span class="line">soup &#x3D; BeautifulSoup(demo, &#39;html.parser&#39;)</span><br><span class="line">tag &#x3D; soup.a</span><br><span class="line">print(soup.a.name)</span><br><span class="line">print(soup.a.parent.name)</span><br><span class="line">print(soup.a.parent.parent.name)</span><br></pre></td></tr></table></figure>
<p><strong>获取Attributes的方法</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;python123.io&#x2F;ws&#x2F;demo.html&#39;)</span><br><span class="line">demo &#x3D; r.text #获取网站的源代码</span><br><span class="line">soup &#x3D; BeautifulSoup(demo, &#39;html.parser&#39;)</span><br><span class="line">tag &#x3D; soup.a</span><br><span class="line">print(tag.attrs)</span><br><span class="line">print(tag.attrs[&#39;class&#39;]) #获取class对应的值</span><br><span class="line">print(tag.attrs[&#39;href&#39;]) #获取标签链接</span><br><span class="line">print(type(tag.attrs)) #获取标签属性的类型</span><br></pre></td></tr></table></figure>
<p><strong>获取NavigableString的方法</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;python123.io&#x2F;ws&#x2F;demo.html&#39;)</span><br><span class="line">demo &#x3D; r.text #获取网站的源代码</span><br><span class="line">soup &#x3D; BeautifulSoup(demo, &#39;html.parser&#39;)</span><br><span class="line">print(soup.a.string)</span><br><span class="line">print((soup.p.string))</span><br><span class="line">print(type(soup.p.string))</span><br></pre></td></tr></table></figure>
<p><strong>获取Comment的方法</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;python123.io&#x2F;ws&#x2F;demo.html&#39;)</span><br><span class="line">demo &#x3D; r.text #获取网站的源代码</span><br><span class="line">soup &#x3D; BeautifulSoup(demo, &#39;html.parser&#39;)</span><br><span class="line">print(soup.p)</span><br><span class="line">newsoup &#x3D; BeautifulSoup(&#39;&lt;p class&#x3D;&quot;title&quot;&gt;&lt;b&gt;The demo python introduces several python courses.&lt;&#x2F;b&gt;&lt;&#x2F;p&gt;&#39;, &#39;html.parser&#39;)</span><br><span class="line">print(newsoup.b.string)</span><br><span class="line">print(type(newsoup.b.string))</span><br></pre></td></tr></table></figure>
<h1 id="基于bs4库的HTML内容遍历方法"><a href="#基于bs4库的HTML内容遍历方法" class="headerlink" title="基于bs4库的HTML内容遍历方法"></a>基于bs4库的HTML内容遍历方法</h1><p><img src="https://i.loli.net/2020/06/11/VOEiaJBo3fGAF1t.png" alt="HTML基本格式及三种遍历方法"></p>
<p><strong>标签树的下行遍历</strong></p>
<table>
<thead>
<tr>
<th align="center">属性</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">.contents</td>
<td align="center">子节点的列表，将&lt; tag &gt;所有儿子节点存入列表</td>
</tr>
<tr>
<td align="center">.children</td>
<td align="center">子节点的迭代类型，与.contents类似，用于循环遍历儿子节点</td>
</tr>
<tr>
<td align="center">.descendants</td>
<td align="center">子孙节点的迭代类型，包含所有子孙节点，用于循环遍历</td>
</tr>
</tbody></table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;python123.io&#x2F;ws&#x2F;demo.html&#39;)</span><br><span class="line">demo &#x3D; r.text #获取网站的源代码</span><br><span class="line">soup &#x3D; BeautifulSoup(demo, &#39;html.parser&#39;)</span><br><span class="line">print(soup.head)</span><br><span class="line">print(soup.head.contents)</span><br><span class="line">print(soup.body.contents)</span><br><span class="line">print(soup.body.contents[1])</span><br></pre></td></tr></table></figure>
<p>遍历儿子节点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for child in soup.body.children:</span><br><span class="line">    pirnt(child)</span><br></pre></td></tr></table></figure>
<p><strong>标签树的上行遍历</strong></p>
<table>
<thead>
<tr>
<th align="center">属性</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">.parent</td>
<td align="center">节点的父亲标签</td>
</tr>
<tr>
<td align="center">.parents</td>
<td align="center">节点先辈标签的迭代类型，用于循环遍历先辈节点</td>
</tr>
</tbody></table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">soup &#x3D; BeautifulSoup(demo, &#39;html.parser&#39;)</span><br><span class="line">for parent in soup.a.parents:</span><br><span class="line">    if parent is None:</span><br><span class="line">        print(parent)</span><br><span class="line">    else:</span><br><span class="line">        print(parent.name) #打印soup.a标签所有的先辈</span><br></pre></td></tr></table></figure>
<p><strong>标签树的平行遍历</strong></p>
<table>
<thead>
<tr>
<th align="center">属性</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">.next_sibling</td>
<td align="center">返回按照HTML文本顺序的下一个平行节点标签</td>
</tr>
<tr>
<td align="center">.previous_sibling</td>
<td align="center">返回按照HTML文本顺序的上一 个平行节点标签</td>
</tr>
<tr>
<td align="center">.next_siblings</td>
<td align="center">迭代类型，返回按照HTML文本顺序的后续所有平行节点标签</td>
</tr>
<tr>
<td align="center">.previous_siblings</td>
<td align="center">迭代类型，返回按照HTML文本顺序的前续所有平行节点标签</td>
</tr>
</tbody></table>
<p><img src="https://i.loli.net/2020/06/11/PKTVZSgwBEQtL6a.png" alt="平行遍历发生在同一个父节点下的各节点间"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">soup &#x3D; BeautifulSoup(demo, &#39;html.parser&#39;)</span><br><span class="line">print(soup.a.next_sibling) #NavigableString也构成了节点</span><br><span class="line">print(soup.a.next_sibling.next_sibling)</span><br><span class="line">print(soup.a.previous_sibling)</span><br><span class="line">print(soup.a.parent)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#对标签树进行循环遍历</span><br><span class="line">for sibling in soup.a.next_siblings:</span><br><span class="line">    print(sibling)  #遍历后续节点</span><br><span class="line">for sibling in soup.a.previous_siblings:</span><br><span class="line">    print(sibling)  #遍历前续节点</span><br></pre></td></tr></table></figure>


<p><strong>遍历类型总结</strong></p>
<p><img src="https://i.loli.net/2020/06/11/Jh4sljIbeLHQoMy.png" alt=""></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/11/%E5%88%B0%E6%AD%A4%E4%B8%BA%E6%AD%A2/">到此为止</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-11</time><div class="content"><h1 id="到此为止"><a href="#到此为止" class="headerlink" title="到此为止"></a>到此为止</h1><p>走到现在这一步其实在我的意料之中。<br>最开始接触你我以为你是一个开朗的女孩儿，但是越接触我越能感觉到你身上无止境的负能量和像无底洞一样的抱怨和埋怨。<br>每天都在说好烦啊烦死了。学习工作压力一大，烦死不爽和叹气就挂在你的嘴边。我就像你身边的垃圾桶，负面情绪的处理站。<br>我最难熬的是大一下的期末，11门考试排的很密，而且还要做物理实验。那一个月，你每天都在抱怨，抱怨完寝室抱怨实验，抱怨完实验抱怨考试。<br>我每天都在如履薄冰，一边承受着和你同样的压力，一边接受你每天高强度的抱怨和负面情绪，不敢疏导，生怕俩人又开始生气吵架。<br>可能是我在家太舒坦了，我现在真不知道我当时是怎么忍受过来而没有崩溃的。<br>哪怕就是心理医生，也很难承受这样的高强度折磨吧？<br>聊天搜素里输入一个烦字，一拉就是一串，密密麻麻。<br>记得就在几星期前，你又开始因为一些琐碎的小事各种怨气缠身，聊天记录全都是烦死了，我好烦，真烦。<br>我在电脑这边实在是忍受不了了，情绪突然变得暴躁，用拳头疯狂锤桌子，然后把手边的草稿纸撕得粉碎，无力地坐在椅子上，心跳很快。<br>然后我平静了一下，聊天框里打出：没事啦宝贝 不用烦。<br>换到一年前，我根本想不到我这种正能量充电器会变得这样狂躁。<br>我知道，这个情况不解决，疙瘩早晚在那里，迟早得要解决。<br>昨天你对我说，既然你接受不了我的负面情绪，就别再委屈自己了，对自己好一点？<br>嗯，好。        </p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/07/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%EF%BC%88%E7%AC%AC1%E5%91%A8%20%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E8%A7%84%E5%88%99%EF%BC%89/">Python网络爬虫与信息提取（第1周 网络爬虫规则）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-07</time><div class="content"><h1 id="单元一-Requests库入门"><a href="#单元一-Requests库入门" class="headerlink" title="单元一 Requests库入门"></a>单元一 Requests库入门</h1><hr>
<h2 id="Requests库的安装"><a href="#Requests库的安装" class="headerlink" title="Requests库的安装"></a>Requests库的安装</h2><p>命令行内输入<code>pip install requests</code>进行安装</p>
<h2 id="Requests库的测试"><a href="#Requests库的测试" class="headerlink" title="Requests库的测试"></a>Requests库的测试</h2><p>IDLE内输入以下代码： </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">r &#x3D; requests.get(&quot;http:&#x2F;&#x2F;www.baidu.com&quot;)</span><br><span class="line">r.status_code</span><br></pre></td></tr></table></figure>
<p>返回<code>200</code>   </p>
<p>说明Requests库安装成功</p>
<h2 id="Requests库语法"><a href="#Requests库语法" class="headerlink" title="Requests库语法"></a>Requests库语法</h2><p><strong>Requests库的七个主要方法</strong>  </p>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">requests.requests()</td>
<td align="center">构造一个请求，支撑以下各方法的基础方法</td>
</tr>
<tr>
<td align="center">requests.get()</td>
<td align="center">获取HTML网页的主要方法，对应HTTP的GET</td>
</tr>
<tr>
<td align="center">requests.head()</td>
<td align="center">获取HTML头信息的方法，对应HTTP的HEAD</td>
</tr>
<tr>
<td align="center">requests.post()</td>
<td align="center">向HTML网页提交POST请求的方法，对应HTTP的POST</td>
</tr>
<tr>
<td align="center">requests.put()</td>
<td align="center">向HTML网页提交PUT请求的方法，对应于HTTP的PUT</td>
</tr>
<tr>
<td align="center">requests.patch()</td>
<td align="center">向HTML网页提交局部修改请求，对应于HTTP的PATCH</td>
</tr>
<tr>
<td align="center">requests.delete()</td>
<td align="center">向HTML页面提交删除请求，对应于HTTP的DELETE</td>
</tr>
</tbody></table>
<h2 id="Response对象的属性"><a href="#Response对象的属性" class="headerlink" title="Response对象的属性"></a>Response对象的属性</h2><table>
<thead>
<tr>
<th align="center">属性</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">r.status_code</td>
<td align="center">HTTP请求的返回状态，200表示连接成功，404表示失败</td>
</tr>
<tr>
<td align="center">r.text</td>
<td align="center">HTTP响应内容的字符串形式，即，url对应的页面内容</td>
</tr>
<tr>
<td align="center">r.encoding</td>
<td align="center">从HTTP header中猜测的响应内容编码方式</td>
</tr>
<tr>
<td align="center">r.apparent_encoding</td>
<td align="center">从内容中分析出的响应内容编码方式(备选编码方式)</td>
</tr>
<tr>
<td align="center">r.content</td>
<td align="center">HTTP响应内容的二进制形式</td>
</tr>
</tbody></table>
<p><em>备注:</em>  </p>
<p>r.encoding:如果header中不存在charset,则认为编码为IS0-8859-1    </p>
<p>rapparent encoding：根据网页内容分析出的编码方式</p>
<h2 id="爬取网页的通用代码框架"><a href="#爬取网页的通用代码框架" class="headerlink" title="爬取网页的通用代码框架"></a>爬取网页的通用代码框架</h2><p><strong>Requests库的六种异常处理</strong></p>
<table>
<thead>
<tr>
<th align="center">异常</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">requests.ConnectionError</td>
<td align="center">网络连接错误异常，如DNS查询失败、拒绝连接等</td>
</tr>
<tr>
<td align="center">requests.HTTPError</td>
<td align="center">HTTP错误异常</td>
</tr>
<tr>
<td align="center">requests.URLRequired</td>
<td align="center">URL缺失异常</td>
</tr>
<tr>
<td align="center">requests.TooManyRedirects</td>
<td align="center">超过最大重定向次数，产生重定向异常</td>
</tr>
<tr>
<td align="center">requests.ConnectTimeout</td>
<td align="center">连接远程服务器超时异常</td>
</tr>
<tr>
<td align="center">requests.Timeout</td>
<td align="center">请求URL超时，产生超时异常</td>
</tr>
</tbody></table>
<p>对于Response：</p>
<table>
<thead>
<tr>
<th align="center">异常</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">r.raise_ for_ status()</td>
<td align="center">如果不是200，产生异常requests.HTTPError</td>
</tr>
</tbody></table>
<p><strong>爬虫时务必使用try-except语句排除异常</strong></p>
<h2 id="HTTP协议及Requests库主要方法"><a href="#HTTP协议及Requests库主要方法" class="headerlink" title="HTTP协议及Requests库主要方法"></a>HTTP协议及Requests库主要方法</h2><h4 id="HTTP基础知识"><a href="#HTTP基础知识" class="headerlink" title="HTTP基础知识"></a>HTTP基础知识</h4><p>HTTP, Hypertext Transfer Protocol, 超文本传输协议。     </p>
<p>HTTP是一个基于“请求与响应”模式的、无状态的应用层协议。      </p>
<p>HTTP协议采用URL作为定位网络资源的标识。</p>
<p><strong>URL格式</strong>   <a href="http://host[:port][path]">http://host[:port][path]</a><br><strong>host</strong> : 合法的Internet主机域名或IP地址<br><strong>port</strong> : 端口号，缺省端口为80<br><strong>path</strong> : 请求资源的路径<br><strong>HTTP协议对资源的操作</strong></p>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">GET</td>
<td align="center">请求获取URL位置的资源</td>
</tr>
<tr>
<td align="center">HEAD</td>
<td align="center">请求获取URL位置资源的响应消息报告，即获得该资源的头部信息</td>
</tr>
<tr>
<td align="center">POST</td>
<td align="center">请求向URL位置的资源后附加新的数据</td>
</tr>
<tr>
<td align="center">PUT</td>
<td align="center">请求向URL位置存储一个资源，覆盖原URL位置的资源</td>
</tr>
<tr>
<td align="center">PATCH</td>
<td align="center">请求局部更新URL位置的资源，即改变该处资源的部分内容</td>
</tr>
<tr>
<td align="center">DELETE</td>
<td align="center">请求删除URL位置存储的资源</td>
</tr>
</tbody></table>
<p>HTTP协议操作与Requests库的方法是一致的</p>
<h3 id="Requests库主要方法解析"><a href="#Requests库主要方法解析" class="headerlink" title="Requests库主要方法解析"></a>Requests库主要方法解析</h3><p>**kwargs:控制访问的参数，均为可选项，包括以下13种       </p>
<p><strong>params</strong> : 字典或字节序列，作为参数增加到url中<br><strong>data</strong> : 字典、字节序列或文件对象，作为Request的内容<br><strong>json</strong> : JSON格式的数据，作为Request的内容<br><strong>headers</strong> : 字典，HTTP定制头<br><strong>cookies</strong> ： 字典或CookieJar, Request中的cookie<br><strong>auth</strong> : 元组，支持HTTP认证功能<br><strong>files</strong> : 字典类型，传输文件<br><strong>timeout</strong> : 设定超时时间，秒为单位<br><strong>proxies</strong> : 字典类型，设定访问代理服务器，可以增加登录认证<br><strong>allow_redirects</strong> : True/False, 默认为True,重定向开关<br><strong>stream</strong> : True/False, 默认为True,获取内容立即下载开关<br><strong>verify</strong> : True/False, 默认为True,认证SSL证书开关<br><strong>cert</strong> : 本地SSL证书路径    </p>
<hr>
<h1 id="单元二-网络爬虫的“盗亦有道”"><a href="#单元二-网络爬虫的“盗亦有道”" class="headerlink" title="单元二 网络爬虫的“盗亦有道”"></a>单元二 网络爬虫的“盗亦有道”</h1><h2 id="网络爬虫的尺寸"><a href="#网络爬虫的尺寸" class="headerlink" title="网络爬虫的尺寸"></a>网络爬虫的尺寸</h2><table>
<thead>
<tr>
<th align="center">规模</th>
<th align="center">特点</th>
<th align="center">库</th>
</tr>
</thead>
<tbody><tr>
<td align="center">爬取网页 玩转网页</td>
<td align="center">小规模 数据量小 爬取速度不敏感</td>
<td align="center">Requests库</td>
</tr>
<tr>
<td align="center">爬取网站 爬取系列网站</td>
<td align="center">中规模 数据规模较大 爬取速度敏感</td>
<td align="center">Scrapy库</td>
</tr>
<tr>
<td align="center">爬取全网</td>
<td align="center">大规模 搜索引擎 爬取速度关键</td>
<td align="center">定制开发</td>
</tr>
</tbody></table>
<h2 id="网络爬虫的限制"><a href="#网络爬虫的限制" class="headerlink" title="网络爬虫的限制"></a>网络爬虫的限制</h2><p><strong>·来源审查:判断User-Agent进行限制</strong>     </p>
<p>检查来访HTTP协议头的User-Agent域，只响应浏览器或友好爬虫的访问。     </p>
<p><strong>·发布公告: Robots协议</strong>      </p>
<p>告知所有爬虫网站的爬取策略，要求爬虫遵守。</p>
<h2 id="Robots协议"><a href="#Robots协议" class="headerlink" title="Robots协议"></a>Robots协议</h2><p>Robots Exclusion Standard网络爬虫排除标准   </p>
<p>作用:网站告知网络爬虫哪些页面可以抓取，哪些不行。   </p>
<p>形式:在网站根目录下的robots.txt文件。  </p>
<p><strong><em>Robots协议基本语法:</em></strong>     </p>
<p>*代表所有，/代表根目录    </p>
<p>User-agent : *  </p>
<p>Disallow : /    </p>
<hr>
<h1 id="单元三-Requests库网络爬虫实例"><a href="#单元三-Requests库网络爬虫实例" class="headerlink" title="单元三 Requests库网络爬虫实例"></a>单元三 Requests库网络爬虫实例</h1><h2 id="实例1：京东商品页面的爬取"><a href="#实例1：京东商品页面的爬取" class="headerlink" title="实例1：京东商品页面的爬取"></a>实例1：京东商品页面的爬取</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">url &#x3D; &quot;https:&#x2F;&#x2F;item.jd.com&#x2F;100002756531.html&quot;</span><br><span class="line">try:</span><br><span class="line">    r &#x3D; requests.get(url)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding &#x3D; r.apparent_encoding</span><br><span class="line">    print(r.text[:1000])</span><br><span class="line">except:</span><br><span class="line">    print(&quot;爬取失败&quot;)</span><br></pre></td></tr></table></figure>
<h2 id="实例2：亚马逊商品页面的爬取"><a href="#实例2：亚马逊商品页面的爬取" class="headerlink" title="实例2：亚马逊商品页面的爬取"></a>实例2：亚马逊商品页面的爬取</h2><p><strong>需要注意的是，要隐藏Python请求的user-agent</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">url &#x3D; &quot;https:&#x2F;&#x2F;www.amazon.cn&#x2F;dp&#x2F;B076YGLN6G?smid&#x3D;A3TEGLC21NOO5Y&amp;ref_&#x3D;Oct_CBBBCard_dsk_asin3&amp;pf_rd_r&#x3D;2TZ4NZR97BGR1G2W8E38&amp;pf_rd_p&#x3D;5a0738df-7719-4914-81ee-278221dce082&amp;pf_rd_m&#x3D;A1AJ19PSB66TGU&amp;pf_rd_s&#x3D;desktop-3&quot;</span><br><span class="line">try:</span><br><span class="line">    kv &#x3D; &#123;&#39;user-agent&#39; : &#39;Mozilla&#x2F;5.0&#39;&#125;</span><br><span class="line">    r &#x3D; requests.get(url,headers&#x3D;kv)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding &#x3D; r.apparent_encoding</span><br><span class="line">    print(r.text[1000:2000])</span><br><span class="line">except:</span><br><span class="line">    print(&quot;爬取失败&quot;)</span><br></pre></td></tr></table></figure>
<h2 id="实例3：百度-360搜索关键词提交"><a href="#实例3：百度-360搜索关键词提交" class="headerlink" title="实例3：百度/360搜索关键词提交"></a>实例3：百度/360搜索关键词提交</h2><p><strong>搜索引擎关键词提交接口</strong><br>百度的关键词接口: <a href="http://www.baidu.com/s?wd=keyword" target="_blank" rel="noopener">http://www.baidu.com/s?wd=keyword</a>     </p>
<p>360的关键词接口: <a href="http://www.so.com/s?q=keyword" target="_blank" rel="noopener">http://www.so.com/s?q=keyword</a>        </p>
<p>只需要替换keyword即可完成搜索</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">keyword &#x3D; &quot; Python&quot;</span><br><span class="line">try:</span><br><span class="line">    kv &#x3D; &#123;&#39;wd&#39;:&#39;Python&#39;&#125;</span><br><span class="line">    r &#x3D; requests.get(&quot;http:&#x2F;&#x2F;www.baidu.com&#x2F;s&quot;,params&#x3D;kv)</span><br><span class="line">    print(r.request.url)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    print(len(r.text))</span><br><span class="line">except :</span><br><span class="line">    print(&quot;爬取失败&quot;)</span><br></pre></td></tr></table></figure>

<p>**⚠如上代码执行后仍不能获取搜索结果，在Python Shell中len(r.tetx) = 0.      </p>
<p>在Pycharm中执行后发现，结果会返回一个验证链接，打开后要求旋转图片。**</p>
<p><img src="https://i.loli.net/2020/06/08/u3dPTHWxmcSfh1Y.png" alt=""></p>
<p><strong>2020/6/8 目前尚无能力解决，此处留一个记号，将来学会了再进行处理</strong></p>
<h2 id="实例4：网络图片的爬取和存储"><a href="#实例4：网络图片的爬取和存储" class="headerlink" title="实例4：网络图片的爬取和存储"></a>实例4：网络图片的爬取和存储</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import os</span><br><span class="line">url &#x3D; &quot;http:&#x2F;&#x2F;img0.dili360.com&#x2F;pic&#x2F;2020&#x2F;05&#x2F;14&#x2F;5ebd27942d9ce1d29634596_t.jpg@!rw4&quot;</span><br><span class="line">root &#x3D; &#39;D:&#39;</span><br><span class="line">path &#x3D; root + url.split(&#39;&#x2F;&#39;)[-1]</span><br><span class="line">try:</span><br><span class="line">    if not os.path.exists(root):</span><br><span class="line">        os.mkdir(root)</span><br><span class="line">    if not os.path.exists(path):</span><br><span class="line">        r &#x3D; requests.get(url)</span><br><span class="line">        with open(path,&#39;wb&#39;) as f:</span><br><span class="line">            f.write(r.content)</span><br><span class="line">            f.close()</span><br><span class="line">        print(&quot;文件保存成功&quot;)</span><br><span class="line">    else:</span><br><span class="line">        print(&quot;文件已存在&quot;)</span><br><span class="line">except:</span><br><span class="line">    print(&quot;爬取失败&quot;)</span><br></pre></td></tr></table></figure>
<h2 id="实例5：IP地址归属地的自动查询"><a href="#实例5：IP地址归属地的自动查询" class="headerlink" title="实例5：IP地址归属地的自动查询"></a>实例5：IP地址归属地的自动查询</h2><p>通过<strong><em>ip138</em></strong>网站进行自动查询</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">url &#x3D; &quot;http:&#x2F;&#x2F;m.ip138.com&#x2F;ip.asp?ip&#x3D;&quot;</span><br><span class="line">try:</span><br><span class="line">    r &#x3D; requests.get(url+&#39;202.198.16.83&#39;)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding &#x3D; r.apparent_encoding</span><br><span class="line">    print(r.text[-500:])</span><br><span class="line">except:</span><br><span class="line">    print(&quot;爬取失败&quot;)</span><br></pre></td></tr></table></figure>



















</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/07/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%EF%BC%88%E7%AC%AC0%E5%91%A8%20%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%89%8D%E5%A5%8F%EF%BC%89/">Python网络爬虫与信息提取（第0周 网络爬虫前奏）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-07</time><div class="content"><p>引言：最近在学习北理嵩天的这门课，便在个人博客里做一下笔记，方面以后学习使用。</p>
<hr>
<h1 id="1-课程内容导学"><a href="#1-课程内容导学" class="headerlink" title="1.课程内容导学"></a>1.课程内容导学</h1><h2 id="Requests库"><a href="#Requests库" class="headerlink" title="Requests库"></a>Requests库</h2><p>自动爬取HTML页面 自动网络提交请求</p>
<h2 id="robots-txt"><a href="#robots-txt" class="headerlink" title="robots.txt"></a>robots.txt</h2><p>网络爬虫排除协议</p>
<h2 id="Beautiful-Soup"><a href="#Beautiful-Soup" class="headerlink" title="Beautiful Soup"></a>Beautiful Soup</h2><p>解析HTML页面</p>
<h2 id="Projects"><a href="#Projects" class="headerlink" title="Projects"></a>Projects</h2><p>实战项目A/B</p>
<h2 id="Re"><a href="#Re" class="headerlink" title="Re"></a>Re</h2><p>正则表达式详解 提取页面关键信息</p>
<h2 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy*"></a>Scrapy*</h2><p>网络爬虫原理介绍 专业爬虫框架介绍</p>
<hr>
<h1 id="2-IDE选择"><a href="#2-IDE选择" class="headerlink" title="2.IDE选择"></a>2.IDE选择</h1><p>目前我自己使用的文本工具类IDE是<strong><em>Sublime Text3</em></strong>,集成工具类IDE是<strong><em>PyCharm</em></strong>。   </p>
<p>等这个课学完，下一个学习数据处理和分析课，再学习使用<strong><em>Anaconda</em></strong>。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/05/31/Python+Selenium%20Auto-Clock/">Python+Selenium Auto-Clock</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-05-31</time><div class="content"><h1 id="Python-Selenium实现吉林大学健康申报自动打卡"><a href="#Python-Selenium实现吉林大学健康申报自动打卡" class="headerlink" title="Python+Selenium实现吉林大学健康申报自动打卡"></a>Python+Selenium实现吉林大学健康申报自动打卡</h1><p>引言：因为自己总是忘记学校打卡，经常让班长提醒，便想着能不能写一个脚本实现自动打卡。在网上查了很多资料琢磨了三四天，最终选择了Python+Selenium完成此项。Selenium库是一种模拟浏览器进行自动化操作的库，可通过此库来完成自动打卡。</p>
<p><strong><em>初学者，代码冗长，如有更优解，烦请指点。</em></strong></p>
<h2 id="0-流程图"><a href="#0-流程图" class="headerlink" title="0.流程图"></a>0.流程图</h2><p><img src="https://i.loli.net/2020/06/04/tTVOWBozMrpwA5u.png" alt=""></p>
<hr>
<h2 id="1-配置工作"><a href="#1-配置工作" class="headerlink" title="1.配置工作"></a>1.配置工作</h2><h3 id="①准备好Python3环境"><a href="#①准备好Python3环境" class="headerlink" title="①准备好Python3环境"></a>①准备好Python3环境</h3><h3 id="②其次根据浏览器的种类及版本，选择相对应的浏览器驱动（driver）"><a href="#②其次根据浏览器的种类及版本，选择相对应的浏览器驱动（driver）" class="headerlink" title="②其次根据浏览器的种类及版本，选择相对应的浏览器驱动（driver）"></a>②其次根据浏览器的种类及版本，选择相对应的浏览器驱动（driver）</h3><p>例如我的浏览器是Chrome的如下版本：</p>
<p><img src="https://i.loli.net/2020/05/31/O1YpRhxCos3vm5V.png" alt=""></p>
<p>然后我们打开<a href="http://npm.taobao.org/mirrors/chromedriver" target="_blank" rel="noopener">Chrome驱动镜像网站</a>，下载对应版本的驱动（如果没找到可以试试略低于自己版本的）。  </p>
<p>安装驱动到工程路径上。(通常至于Python文件夹下的Scripts文件夹内)</p>
<h3 id="③配置浏览器驱动"><a href="#③配置浏览器驱动" class="headerlink" title="③配置浏览器驱动"></a>③配置浏览器驱动</h3><p>我们需要将浏览器驱动路径加入到环境变量中，完成配置   </p>
<h4 id="右键【此电脑】，打开属性-R-选择左边的高级系统设置"><a href="#右键【此电脑】，打开属性-R-选择左边的高级系统设置" class="headerlink" title="右键【此电脑】，打开属性(R),选择左边的高级系统设置"></a>右键【此电脑】，打开属性(R),选择左边的高级系统设置</h4><p><img src="https://i.loli.net/2020/06/08/IazdnvjSo6QU8mx.png" alt=""></p>
<h4 id="点击环境变量"><a href="#点击环境变量" class="headerlink" title="点击环境变量"></a>点击环境变量</h4><p><img src="https://i.loli.net/2020/06/08/Q1SuxdM9ntWU3wk.png" alt=""></p>
<h4 id="选择Path编辑，新建后输入浏览器驱动所在路径"><a href="#选择Path编辑，新建后输入浏览器驱动所在路径" class="headerlink" title="选择Path编辑，新建后输入浏览器驱动所在路径"></a>选择Path编辑，新建后输入浏览器驱动所在路径</h4><p><img src="https://i.loli.net/2020/06/08/fjZWBILa8p3qzMC.png" alt=""></p>
<h3 id="④安装Selenium库"><a href="#④安装Selenium库" class="headerlink" title="④安装Selenium库"></a>④安装Selenium库</h3><p>打开命令行，输入<code>pip install selenium</code>  </p>
<p>关于selenium库的具体用法，我们可以参考如下链接：    </p>
<p><a href="http://www.selenium.org.cn/1598.html" target="_blank" rel="noopener">Selenium中文网</a>     </p>
<p><a href="https://blog.csdn.net/weixin_36279318/article/details/79475388" target="_blank" rel="noopener">Python Selenium库的使用</a>       </p>
<p>由于我们之后还会用到js命令，所以需要再安装<code>pip install js2py</code></p>
<h3 id="⑤事先录入一遍信息"><a href="#⑤事先录入一遍信息" class="headerlink" title="⑤事先录入一遍信息"></a>⑤事先录入一遍信息</h3><p>为了方便写代码，我们需要打开申报表，先填写一边信息并提交。   </p>
<p>这样的话浏览器会自动存储已经填好的信息，我们只需要点点点确认就可以了。</p>
<hr>
<h2 id="2-脚本分析"><a href="#2-脚本分析" class="headerlink" title="2.脚本分析"></a>2.脚本分析</h2><h3 id="①引用库"><a href="#①引用库" class="headerlink" title="①引用库"></a>①引用库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入selenium里的webdriver包</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> js2py</span><br><span class="line"><span class="comment"># noinspection PyUnresolvedReferences</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys <span class="comment">#输入账号密码时会用到</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options<span class="comment">#转换标签页时会用到</span></span><br></pre></td></tr></table></figure>
<h3 id="②打开吉林大学办事大厅"><a href="#②打开吉林大学办事大厅" class="headerlink" title="②打开吉林大学办事大厅"></a>②打开吉林大学办事大厅</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">driver = webdriver.Chrome()</span><br><span class="line">driver.get(<span class="string">"https://ehall.jlu.edu.cn/taskcenter/workflow/appall"</span>)<span class="comment">#打开吉林大学办事大厅</span></span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="③定位账号密码并点击登录，"><a href="#③定位账号密码并点击登录，" class="headerlink" title="③定位账号密码并点击登录，"></a>③定位账号密码并点击登录，</h3><p>我在这个界面使用的是by_id方法定位账号密码框。<br>将光标放置在账号栏上，右键后点击【检查】，找到该元素的id。<br><img src="https://i.loli.net/2020/05/31/kg8p3nfczUDVXRG.png" alt=""><br>相同方法找出密码框和登录框的id<br><img src="https://i.loli.net/2020/05/31/LM5UoVNG2YWFwPt.png" alt=""></p>
<p><img src="https://i.loli.net/2020/05/31/yvqwmGeJp7K9t5M.png" alt=""><br>定位元素并输入账号密码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#输入用户名和密码 点击登录</span></span><br><span class="line">driver.find_element_by_id(<span class="string">"username"</span>).send_keys(<span class="string">"你的账号"</span>)</span><br><span class="line">driver.find_element_by_id(<span class="string">"password"</span>).send_keys(<span class="string">"你的密码"</span>)</span><br><span class="line">driver.find_element_by_id(<span class="string">"login-submit"</span>).click()</span><br><span class="line">time.sleep(<span class="number">1</span>)<span class="comment">#停1秒再继续操作</span></span><br></pre></td></tr></table></figure>
<h3 id="④点击本科生健康状况申报"><a href="#④点击本科生健康状况申报" class="headerlink" title="④点击本科生健康状况申报"></a>④点击本科生健康状况申报</h3><p>进入到下一页面后，直接用名称进行定位： </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">driver.find_element_by_link_text(<span class="string">"本科生健康状况申报"</span>).click()</span><br><span class="line">time.sleep(<span class="number">4</span>)<span class="comment">#有时候表格加载时间比较长，故sleep四秒</span></span><br></pre></td></tr></table></figure>
<h3 id="⑤切换标签页并下拉滚动条"><a href="#⑤切换标签页并下拉滚动条" class="headerlink" title="⑤切换标签页并下拉滚动条"></a>⑤切换标签页并下拉滚动条</h3><p>这里我卡了好几天，run的时候总是出现<code>ElementNotVisibleException: element not visible</code>    </p>
<p>我以为是我在定位元素的时候出错了，便试了很多种定位方法还是报错。    </p>
<p>最后发现，虽然弹出了新的标签页，但是他还是定位在旧的标签页上。于是用以下代码切换标签页：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n = driver.window_handles</span><br><span class="line">driver.switch_to.window(n[<span class="number">-1</span>])</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>更加详细的解释可以参考<a href="https://blog.csdn.net/u012941152/article/details/88418812?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase" target="_blank" rel="noopener">Selenium新窗口打开链接，并定位到新窗口</a>    </p>
<p>当我切换了标签页后，发现还是无法定位，又经过了十几次尝试，发现当所求元素不在当前屏幕内时，需要调整滚动条至对应位置才能定位。  </p>
<p>由于webdriver无法调整滚动条，故用js语句来实现。   </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">js = <span class="string">"window.scrollTo(0,document.body.scrollHeight)"</span></span><br><span class="line">driver.execute_script(js)</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>更加详细的解释可以参考<a href="http://www.mamicode.com/info-detail-2324043.html" target="_blank" rel="noopener">Selenium浏览器滚动条操作</a>，<a href="https://blog.csdn.net/doulihang/article/details/80835290?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase" target="_blank" rel="noopener">Selenium操作滚动条</a>       </p>
<h3 id="⑥定位点击复选框及确认填报"><a href="#⑥定位点击复选框及确认填报" class="headerlink" title="⑥定位点击复选框及确认填报"></a>⑥定位点击复选框及确认填报</h3><p>在这里我用的是by_xpath进行定位，对于一些动态id或者是嵌套很深的元素，可以用xpath或css的方法来定位。  </p>
<p>光标放在最下面的复选框上，右键检查，再右键右边选中的Elements，按所示路径copy xpath.<br><img src="https://i.loli.net/2020/05/31/ECyi4hDsYlK3pkz.png" alt="">     </p>
<p>同样的方法点击上方的确认填报。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#勾选复选框 点击确认 点击弹窗</span></span><br><span class="line">driver.find_element_by_xpath(<span class="string">'/html/body/div[4]/form/div/div[2]/div[3]/div/div[1]/div[1]/table/tbody/tr[2]/td/div/table/tbody/tr[55]/td/div/input'</span>).click()</span><br><span class="line">driver.find_element_by_xpath(<span class="string">"/html/body/div[4]/form/div/div[1]/div[2]/ul/li[1]/a"</span>).click()</span><br><span class="line">time.sleep(<span class="number">2</span>)<span class="comment">#等待提示框弹出</span></span><br></pre></td></tr></table></figure>
<h3 id="⑦点击弹窗完成，退出浏览器。"><a href="#⑦点击弹窗完成，退出浏览器。" class="headerlink" title="⑦点击弹窗完成，退出浏览器。"></a>⑦点击弹窗完成，退出浏览器。</h3><p>同理定位弹窗内的【好】，并点击，随后关闭浏览器。   </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">driver.find_element_by_xpath(<span class="string">"/html/body/div[7]/div/div[2]/button[1]"</span>).click()</span><br><span class="line">driver.quit()<span class="comment">#自动打卡完成，关闭浏览器</span></span><br></pre></td></tr></table></figure>
<h3 id="⑧启用无头模式-headless-mode-打开浏览器"><a href="#⑧启用无头模式-headless-mode-打开浏览器" class="headerlink" title="⑧启用无头模式(headless mode)打开浏览器"></a>⑧启用无头模式(headless mode)打开浏览器</h3><p>如果每次都要弹出个浏览器等他运行完成以后再关闭属实累赘，于是我们可以再开头设置无头模式，让浏览器在后台自行完成并关闭，不影响台面上的工作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用无头模式打开浏览器</span></span><br><span class="line">ch_options = Options()</span><br><span class="line">ch_options.add_argument(<span class="string">"--headless"</span>)  <span class="comment"># =&gt; 为Chrome配置无头模式</span></span><br><span class="line">driver = webdriver.Chrome(options=ch_options)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="3-完整代码"><a href="#3-完整代码" class="headerlink" title="3.完整代码"></a>3.完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入selenium里的webdriver包</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> js2py</span><br><span class="line"><span class="comment"># noinspection PyUnresolvedReferences</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line"><span class="comment">#用无头模式打开浏览器</span></span><br><span class="line">ch_options = Options()</span><br><span class="line">ch_options.add_argument(<span class="string">"--headless"</span>)  <span class="comment"># =&gt; 为Chrome配置无头模式</span></span><br><span class="line">driver = webdriver.Chrome(options=ch_options)</span><br><span class="line"></span><br><span class="line">driver.get(<span class="string">"https://ehall.jlu.edu.cn/taskcenter/workflow/appall"</span>)<span class="comment">#打开吉林大学办事大厅</span></span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line"><span class="comment">#输入用户名和密码 点击登录</span></span><br><span class="line">driver.find_element_by_id(<span class="string">"username"</span>).send_keys(<span class="string">"你的账号"</span>)</span><br><span class="line">driver.find_element_by_id(<span class="string">"password"</span>).send_keys(<span class="string">"你的密码"</span>)</span><br><span class="line">driver.find_element_by_id(<span class="string">"login-submit"</span>).click()</span><br><span class="line">time.sleep(<span class="number">1</span>)<span class="comment">#停1秒再继续操作</span></span><br><span class="line">driver.find_element_by_link_text(<span class="string">"本科生健康状况申报"</span>).click()</span><br><span class="line">time.sleep(<span class="number">4</span>)<span class="comment">#表格加载四秒</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#这里卡了好几天 最后发现问题是要先切换标签页 再滑动滚动条至底部才能定位元素</span></span><br><span class="line">n = driver.window_handles</span><br><span class="line">driver.switch_to.window(n[<span class="number">-1</span>])</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line">js = <span class="string">"window.scrollTo(0,document.body.scrollHeight)"</span></span><br><span class="line">driver.execute_script(js)</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#勾选复选框 点击确认 点击弹窗</span></span><br><span class="line">driver.find_element_by_xpath(<span class="string">'/html/body/div[4]/form/div/div[2]/div[3]/div/div[1]/div[1]/table/tbody/tr[2]/td/div/table/tbody/tr[55]/td/div/input'</span>).click()</span><br><span class="line">driver.find_element_by_xpath(<span class="string">"/html/body/div[4]/form/div/div[1]/div[2]/ul/li[1]/a"</span>).click()</span><br><span class="line">time.sleep(<span class="number">2</span>)<span class="comment">#等待提示框弹出</span></span><br><span class="line">driver.find_element_by_xpath(<span class="string">"/html/body/div[7]/div/div[2]/button[1]"</span>).click()</span><br><span class="line">driver.quit()<span class="comment">#自动打卡完成，关闭浏览器</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="4-设置开机自动启动"><a href="#4-设置开机自动启动" class="headerlink" title="4.设置开机自动启动"></a>4.设置开机自动启动</h2><p>将完成的脚本创捷快捷方式至桌面     </p>
<p>Win+R打开运行窗口输入shell:startup，打开启动文件夹，将快捷方式拖入文件夹内即可。   </p>
<hr>
<h2 id="5-参考资料"><a href="#5-参考资料" class="headerlink" title="5.参考资料"></a>5.参考资料</h2><p><a href="http://www.selenium.org.cn/1598.html" target="_blank" rel="noopener">http://www.selenium.org.cn/1598.html</a><br><a href="https://blog.csdn.net/weixin_36279318/article/details/79475388" target="_blank" rel="noopener">https://blog.csdn.net/weixin_36279318/article/details/79475388</a><br><a href="https://blog.csdn.net/u012941152/article/details/88418812?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase" target="_blank" rel="noopener">https://blog.csdn.net/u012941152/article/details/88418812?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase</a><br><a href="http://www.mamicode.com/info-detail-2324043.html" target="_blank" rel="noopener">http://www.mamicode.com/info-detail-2324043.html</a><br><a href="https://blog.csdn.net/doulihang/article/details/80835290?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase" target="_blank" rel="noopener">https://blog.csdn.net/doulihang/article/details/80835290?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/05/12/hello-world/">Hello World</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-05-12</time><div class="content"><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
</div><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://i.loli.net/2020/05/12/jFsUgX9TBbnQu2o.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2020 By LyC</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>