<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="药学 自由人 爱好者"><meta name="keywords" content=""><meta name="author" content="LyC"><meta name="copyright" content="LyC"><title>莫道君行早 更有早行人 | LyC's Blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="LyC's Blog" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="https://i.loli.net/2020/05/17/HbaOsFvjp8c9MRE.jpg"></div><div class="author-info__name text-center">LyC</div><div class="author-info__description text-center">药学 自由人 爱好者</div><div class="follow-button"><a href="https://jluliyuxi.github.io/">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">16</span></a></div></div></div><nav id="nav" style="background-image: url(https://i.loli.net/2020/05/12/jFsUgX9TBbnQu2o.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">LyC's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="site-info"><div id="site-title">LyC's Blog</div><div id="site-sub-title">莫道君行早 更有早行人</div><div id="site-social-icons"><a class="social-icon" href="https://github.com/JLUliyuxi || github" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-github fa"></i></a><a class="social-icon" href="https://weibo.com/3687299900/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo || weibo" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-weibo fa"></i></a><a class="social-icon" href="https://www.google.com || chrome" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-chrome fa"></i></a></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2020/07/11/Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%B1%95%E7%A4%BA%EF%BC%88%E7%AC%AC0%E5%91%A8%20%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8B%E8%A1%A8%E7%A4%BA%20%E5%8D%95%E5%85%83%E4%B8%80%20NumPy%E5%BA%93%E5%85%A5%E9%97%A8%EF%BC%89/">Python数据分析与展示（第0周 数据分析之表示 单元一 NumPy库入门）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-07-11</time><div class="content"><h1 id="数据的维度"><a href="#数据的维度" class="headerlink" title="数据的维度"></a>数据的维度</h1><p><strong>维度</strong>：一组数据的组织形式        </p>
<p>一维数据：由对等关系的有序或无序数据构成，采用线性方式组织。      </p>
<p>列表数据类型可以不同，数组数据类型必须相同。      </p>
<p>二维数据：由多个一维数据构成，是一维数据的组合形式。      </p>
<p>数据维度的Python表示：      </p>
<p>一维数据：列表+集合<br>二维数据：列表<br>三维数据：列表     </p>
<h1 id="NumPy的数组对象：ndarray"><a href="#NumPy的数组对象：ndarray" class="headerlink" title="NumPy的数组对象：ndarray"></a>NumPy的数组对象：ndarray</h1><p>NumPy是一个开源的Python科学计算库<br>※一个强大的N维数组对象 ndarray<br>※广播功能函数<br>※整合C/C++/Fortran代码的工具<br>※线性代数、傅里叶变换、随机数生成等功能        </p>
<h2 id="NumPy的引用"><a href="#NumPy的引用" class="headerlink" title="NumPy的引用"></a>NumPy的引用</h2><p><code>import numpy as np</code>引用NumPy库<br><strong>尽量使用约定的别名np</strong></p>
<h2 id="N维度数组对象：ndarray"><a href="#N维度数组对象：ndarray" class="headerlink" title="N维度数组对象：ndarray"></a>N维度数组对象：ndarray</h2><p><strong>例如：计算A平方+B三次方，其中，A和B是一维数组</strong>   </p>
<p><strong>常规方法：</strong>     </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def pySum():</span><br><span class="line">    a &#x3D; [0,1,2,3,4]</span><br><span class="line">    b &#x3D; [9,8,7,6,5]</span><br><span class="line">    c &#x3D; []</span><br><span class="line"></span><br><span class="line">    for i in range(len(a)):</span><br><span class="line">        c.append(a[i]**2 + b[i]**3)</span><br><span class="line"></span><br><span class="line">    return c</span><br><span class="line"></span><br><span class="line">print(pySum())</span><br></pre></td></tr></table></figure>

<p><strong>ndarray方法:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">def npSum():</span><br><span class="line">    a &#x3D; np.array([0,1,2,3,4])</span><br><span class="line">    b &#x3D; np.array([9,8,7,6,5])</span><br><span class="line"></span><br><span class="line">    c &#x3D; a**2 + b**3 #维度相同时可直接进行计算</span><br><span class="line"></span><br><span class="line">    return c</span><br><span class="line"></span><br><span class="line">print(npSum())</span><br></pre></td></tr></table></figure>
<p><strong>※数组对象可以去掉元素间运算所需的循环，使一维向量更像个单个数据。</strong>  </p>
<p><strong>※设置专门的数组对象，经过优化，可以提升这类应用的运算速度。</strong>      </p>
<h2 id="ndarray简述"><a href="#ndarray简述" class="headerlink" title="ndarray简述"></a>ndarray简述</h2><p>ndarray是一个多维数组对象，由两部分组成：    </p>
<p>※实际的数据      </p>
<p>※描述这些数据的元数据（数据维度、数据类型等）     </p>
<p><code>np.array()</code>生成一个ndarray数组<br><em>ndarray在程序中的别名是：array</em>     </p>
<p>np.array()输出成[]形式，元素由空格分割。      </p>
<p><strong>轴(axis)：保存数据的维度</strong>     </p>
<p><strong>秩(rank)：轴的数量</strong>    </p>
<h2 id="ndarray对象的属性"><a href="#ndarray对象的属性" class="headerlink" title="ndarray对象的属性"></a>ndarray对象的属性</h2><table>
<thead>
<tr>
<th align="center">属性</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">.ndim</td>
<td align="center">秩，即轴的数量或维度的数量</td>
</tr>
<tr>
<td align="center">.shape</td>
<td align="center">ndarray对象的尺度，对于矩阵，n行m列</td>
</tr>
<tr>
<td align="center">.size</td>
<td align="center">ndarray对象元素的个数，相当于.shape中n* m的值</td>
</tr>
<tr>
<td align="center">.dtype</td>
<td align="center">ndarray对象的元素类型</td>
</tr>
<tr>
<td align="center">.itemsize</td>
<td align="center">ndarray对象中每个元素的大小，以字节为单位</td>
</tr>
</tbody></table>
<h2 id="ndarray的元素类型"><a href="#ndarray的元素类型" class="headerlink" title="ndarray的元素类型"></a>ndarray的元素类型</h2><p><img src="https://i.loli.net/2020/07/11/VBJsknFgWUYbC5S.png" alt="ndarray的元素类型①"> </p>
<p><img src="https://i.loli.net/2020/07/11/qk7uOPKNmsJF5Ll.png" alt="ndarray的元素类型②"></p>
<p><img src="https://i.loli.net/2020/07/11/HYBQnRzukqpE8Od.png" alt="ndarray的元素类型③"></p>
<h1 id="ndarray数组的创建和变换"><a href="#ndarray数组的创建和变换" class="headerlink" title="ndarray数组的创建和变换"></a>ndarray数组的创建和变换</h1><h2 id="ndarray的创建方法："><a href="#ndarray的创建方法：" class="headerlink" title="ndarray的创建方法："></a>ndarray的创建方法：</h2><p>① 从Python中的列表、元组等类型创建ndarray数组。     </p>
<p><code>x = np.array(list/tuple)</code></p>
<p><code>x = np.array(list/tuple,dtype=np.float32) #指定元素数据类型</code><br>当np.array()不指定dtype时，NumPy将根据数据情况关联一个dtype类型。       </p>
<p>② 使用NumPy中函数创建ndarray数组，如：arange,ones,zeros等。       </p>
<table>
<thead>
<tr>
<th align="center">函数</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">np.arange(n)</td>
<td align="center">类似range(函数，返回ndarray类型， 元素从0到n-1</td>
</tr>
<tr>
<td align="center">np.ones(shape)</td>
<td align="center">根据shape生成一 个全 1数组，shape是元组类型</td>
</tr>
<tr>
<td align="center">np.zeros(shape)</td>
<td align="center">根据shape生成一 个 全0数组，shape是元组类型</td>
</tr>
<tr>
<td align="center">np.full(shape,va1)</td>
<td align="center">根据shape生成一个数组，每个元素值都是val</td>
</tr>
<tr>
<td align="center">np.eye(n)</td>
<td align="center">创建一个正方的n*n单位矩阵，对角线为1，其余为0</td>
</tr>
<tr>
<td align="center">np.ones_like(a)</td>
<td align="center">根据数组a的形状生成一个全1数组</td>
</tr>
<tr>
<td align="center">np.zeros_like(a)</td>
<td align="center">根据数组a的形状生成一个全0数组</td>
</tr>
<tr>
<td align="center">np.full_like(a,val)</td>
<td align="center">根据数组a的形状生成一个数组， 每个元素值都是val</td>
</tr>
<tr>
<td align="center">np.linspace()</td>
<td align="center">根据起止数据等间距地填充数据，形成数组</td>
</tr>
<tr>
<td align="center">np.concatenate()</td>
<td align="center">将两个或多个数组合并成一个新的数组</td>
</tr>
</tbody></table>
<p>③ 从字节流（raw bytes)中创建ndarray数组。</p>
<p>④ 从文件中读取特定格式，创建ndarray数组。</p>
<h2 id="ndarray数组的维度变换"><a href="#ndarray数组的维度变换" class="headerlink" title="ndarray数组的维度变换"></a>ndarray数组的维度变换</h2><table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">.reshape(shape)</td>
<td align="center">不改变数组元素，返回一个shape形状的数组，原数组不变</td>
</tr>
<tr>
<td align="center">.resize(shape)</td>
<td align="center">与.reshape()功能一致， 但修改原数组</td>
</tr>
<tr>
<td align="center">.swapaxes(ax1,ax2)</td>
<td align="center">将数组n个维度中两个维度进行调换</td>
</tr>
<tr>
<td align="center">.flatten()</td>
<td align="center">对数组进行降维，返回折叠后的一维数组，原数组不变</td>
</tr>
</tbody></table>
<h1 id="ndarray数组的操作"><a href="#ndarray数组的操作" class="headerlink" title="ndarray数组的操作"></a>ndarray数组的操作</h1><p>即对数组的<strong>索引</strong>和<strong>切片</strong></p>
<h2 id="一维数组的索引和切片：与Python类似"><a href="#一维数组的索引和切片：与Python类似" class="headerlink" title="一维数组的索引和切片：与Python类似"></a>一维数组的索引和切片：与Python类似</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a &#x3D; np.array([9,8,7,6,5])</span><br><span class="line">a[2] # out:7</span><br><span class="line">a[1:4:2] # out:array([8,6])</span><br></pre></td></tr></table></figure>

<h2 id="多维数组的索引："><a href="#多维数组的索引：" class="headerlink" title="多维数组的索引："></a>多维数组的索引：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a &#x3D; np.arange(24).reshape((2,3,4))</span><br><span class="line">a[1,2,3] # out:23</span><br><span class="line">a[0,1,2] # out:6</span><br><span class="line">a[-1,-2,-3] # out:17</span><br><span class="line">#每个维度一个索引值，用逗号分隔</span><br></pre></td></tr></table></figure>

<h2 id="多维数组的切片："><a href="#多维数组的切片：" class="headerlink" title="多维数组的切片："></a>多维数组的切片：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a &#x3D; np.arange(24).reshape((2,3,4))</span><br><span class="line">a[:,1,-3] # out:array([5,17])</span><br><span class="line">a[:,1:3,:]</span><br><span class="line">a[:,:,::2]</span><br></pre></td></tr></table></figure>

<h1 id="ndarray数组的运算"><a href="#ndarray数组的运算" class="headerlink" title="ndarray数组的运算"></a>ndarray数组的运算</h1><h2 id="数组与标量之间的运算"><a href="#数组与标量之间的运算" class="headerlink" title="数组与标量之间的运算"></a>数组与标量之间的运算</h2><p>数组与标量之间的运算作用于数组的每一个元素       </p>
<p><img src="https://i.loli.net/2020/07/11/DPIQtpvEOHslqJA.png" alt=""></p>
<h2 id="NumPy一元函数"><a href="#NumPy一元函数" class="headerlink" title="NumPy一元函数"></a>NumPy一元函数</h2><table>
<thead>
<tr>
<th align="center">函数</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">np.abs(x) np.fabs(x)</td>
<td align="center">计算数组各元素的绝对值</td>
</tr>
<tr>
<td align="center">np.sqrt(x)</td>
<td align="center">计算数组各元素的平方根</td>
</tr>
<tr>
<td align="center">np.square(x)</td>
<td align="center">计算数组各元素的平方</td>
</tr>
<tr>
<td align="center">np.log(x) np.log10(x) np.log2(x)</td>
<td align="center">计算数组各元素的自然对数、10底对数和2底对数</td>
</tr>
<tr>
<td align="center">np.ceil(x) np.floor(x)</td>
<td align="center">计算数组各 元素的eiling值或noor值</td>
</tr>
<tr>
<td align="center">np.rint(x)</td>
<td align="center">计算数组各元素的四舍五入值</td>
</tr>
<tr>
<td align="center">np.modf(x)</td>
<td align="center">将数组各元素的小数和整数部分以两个独立数组形式返回</td>
</tr>
<tr>
<td align="center">np.cos(x) np.cosh(x)</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">np.sin(x) np.sinh(x)</td>
<td align="center">计算数组各元素的普通型和双曲型三角函数</td>
</tr>
<tr>
<td align="center">np.tan(x) np.tanh(x)</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">np.exp(x)</td>
<td align="center">计算数组各元素的指数值</td>
</tr>
<tr>
<td align="center">np.sign(x)</td>
<td align="center">计算数组各元素的符号值，1(+),0, -1(-)</td>
</tr>
</tbody></table>
<h2 id="NumPy二元函数"><a href="#NumPy二元函数" class="headerlink" title="NumPy二元函数"></a>NumPy二元函数</h2><table>
<thead>
<tr>
<th align="center">函数</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><code>+ - * / **</code></td>
<td align="center">两个数组各元素进行对应运算</td>
</tr>
<tr>
<td align="center">np.maximum(x,y) np.fmax()</td>
<td align="center"></td>
</tr>
<tr>
<td align="center"></td>
<td align="center">元素级的最大值/最小值计算</td>
</tr>
<tr>
<td align="center">np.minimum(x,y) np.fmin()</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">np.mod(x,y)</td>
<td align="center">元素级的模运算</td>
</tr>
<tr>
<td align="center">np.copysign(x,y)</td>
<td align="center">将数组y中各元素值的符号赋值给数组x对应元素</td>
</tr>
<tr>
<td align="center"><code>&gt; &lt; &gt;= &lt;= == !=</code></td>
<td align="center">算术比较，产生布尔型数组</td>
</tr>
</tbody></table>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/07/10/Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%B1%95%E7%A4%BA%EF%BC%88%E7%AC%AC0%E5%91%A8%20%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8B%E5%89%8D%E5%A5%8F%EF%BC%89/">Python数据分析与展示（第0周 数据分析之前奏）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-07-10</time><div class="content"><h1 id="“数据分析”课程内容导学"><a href="#“数据分析”课程内容导学" class="headerlink" title="“数据分析”课程内容导学"></a>“数据分析”课程内容导学</h1><p>NumPy库，Matplotlib库，Pandas库      </p>
<p><strong>摘要</strong>：有损地提取数据特征的过程<br>※基本统计(含排序)<br>※分布/累计统计<br>※数据特征，相关性、周期性等<br>※数据挖掘(形成知识)     </p>
<p><strong><em>建议使用Anaconda IDE</em></strong>      </p>
<p><strong><em>理解和掌握 conda Spyder IPython 的使用</em></strong>        </p>
<p><strong>内容组织</strong>：<br>绘制坐标系、饼图、直方图、极坐标图、散点图<br>实例1：图像的手绘效果<br>实例2：引力波的绘制<br>实例3：房价趋势的关联因素分析<br>实例4：股票数据的趋势分析曲线     </p>
<h1 id="Anaconda-IDE的基本使用"><a href="#Anaconda-IDE的基本使用" class="headerlink" title="Anaconda IDE的基本使用"></a>Anaconda IDE的基本使用</h1><h2 id="包管理和环境管理工具-conda"><a href="#包管理和环境管理工具-conda" class="headerlink" title="包管理和环境管理工具-conda"></a>包管理和环境管理工具-conda</h2><p>包管理与pip类似，管理Python第三方库      </p>
<p>环境管理能够允许用户使用不同版本的Python，并能灵活切换。</p>
<p>启动cmd,执行<code>conda --version</code>，可获取conda版本号</p>
<h2 id="Anaconda-一个集合，包括conda、某版本Python、一批第三方库等。"><a href="#Anaconda-一个集合，包括conda、某版本Python、一批第三方库等。" class="headerlink" title="Anaconda:一个集合，包括conda、某版本Python、一批第三方库等。"></a>Anaconda:一个集合，包括conda、某版本Python、一批第三方库等。</h2><h2 id="编程工具：Spyder"><a href="#编程工具：Spyder" class="headerlink" title="编程工具：Spyder"></a>编程工具：Spyder</h2><p>包括编辑区、文件导航和IPython      </p>
<h2 id="交互式编程环境：IPython"><a href="#交互式编程环境：IPython" class="headerlink" title="交互式编程环境：IPython"></a>交互式编程环境：IPython</h2></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/07/03/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%EF%BC%88%E7%AC%AC4%E5%91%A8%20%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6%20%E7%AC%AC%E5%8D%81%E4%B8%80%E5%8D%95%E5%85%83%20%E8%82%A1%E7%A5%A8%E6%95%B0%E6%8D%AEScrapy%E7%88%AC%E8%99%AB%EF%BC%89/">Python网络爬虫与信息提取（第4周 网络爬虫框架 第十一单元 股票数据Scrapy爬虫）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-07-03</time><div class="content"><h1 id="股票数据Scrapy爬虫实例介绍"><a href="#股票数据Scrapy爬虫实例介绍" class="headerlink" title="股票数据Scrapy爬虫实例介绍"></a>股票数据Scrapy爬虫实例介绍</h1><hr>
<p>获取股票列表:     </p>
<p>东方财富网: <a href="http://quote.eastmoney.com/stocklist.html" target="_blank" rel="noopener">http://quote.eastmoney.com/stocklist.html</a>        </p>
<p>获取个股信息:     </p>
<p>百度股票: <a href="https://gupiao.baidu.com/stock/" target="_blank" rel="noopener">https://gupiao.baidu.com/stock/</a>       </p>
<p>单个股票: <a href="https://gupiao.baidu.com/stock/sz002439.html" target="_blank" rel="noopener">https://gupiao.baidu.com/stock/sz002439.html</a>      </p>
<h1 id="股票数据Scrapy爬虫实例编写"><a href="#股票数据Scrapy爬虫实例编写" class="headerlink" title="股票数据Scrapy爬虫实例编写"></a>股票数据Scrapy爬虫实例编写</h1><h2 id="Stocks-py"><a href="#Stocks-py" class="headerlink" title="Stocks.py"></a>Stocks.py</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">import scrapy</span><br><span class="line">import re</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">class StocksSpider(scrapy.Spider):</span><br><span class="line">    name &#x3D; &quot;stocks&quot;</span><br><span class="line">    start_urls &#x3D; [&#39;https:&#x2F;&#x2F;quote.eastmoney.com&#x2F;stocklist.html&#39;]</span><br><span class="line"> </span><br><span class="line">    def parse(self, response):</span><br><span class="line">        for href in response.css(&#39;a::attr(href)&#39;).extract():</span><br><span class="line">            try:</span><br><span class="line">                stock &#x3D; re.findall(r&quot;[s][hz]\d&#123;6&#125;&quot;, href)[0]</span><br><span class="line">                url &#x3D; &#39;https:&#x2F;&#x2F;gupiao.baidu.com&#x2F;stock&#x2F;&#39; + stock + &#39;.html&#39;</span><br><span class="line">                yield scrapy.Request(url, callback&#x3D;self.parse_stock)</span><br><span class="line">            except:</span><br><span class="line">                continue</span><br><span class="line"> </span><br><span class="line">    def parse_stock(self, response):</span><br><span class="line">        infoDict &#x3D; &#123;&#125;</span><br><span class="line">        stockInfo &#x3D; response.css(&#39;.stock-bets&#39;)</span><br><span class="line">        name &#x3D; stockInfo.css(&#39;.bets-name&#39;).extract()[0]</span><br><span class="line">        keyList &#x3D; stockInfo.css(&#39;dt&#39;).extract()</span><br><span class="line">        valueList &#x3D; stockInfo.css(&#39;dd&#39;).extract()</span><br><span class="line">        for i in range(len(keyList)):</span><br><span class="line">            key &#x3D; re.findall(r&#39;&gt;.*&lt;&#x2F;dt&gt;&#39;, keyList[i])[0][1:-5]</span><br><span class="line">            try:</span><br><span class="line">                val &#x3D; re.findall(r&#39;\d+\.?.*&lt;&#x2F;dd&gt;&#39;, valueList[i])[0][0:-5]</span><br><span class="line">            except:</span><br><span class="line">                val &#x3D; &#39;--&#39;</span><br><span class="line">            infoDict[key]&#x3D;val</span><br><span class="line"> </span><br><span class="line">        infoDict.update(</span><br><span class="line">            &#123;&#39;股票名称&#39;: re.findall(&#39;\s.*\(&#39;,name)[0].split()[0] + \</span><br><span class="line">             re.findall(&#39;\&gt;.*\&lt;&#39;, name)[0][1:-1]&#125;)</span><br><span class="line">        yield infoDict</span><br></pre></td></tr></table></figure>

<h2 id="Pipelines-py"><a href="#Pipelines-py" class="headerlink" title="Pipelines.py"></a>Pipelines.py</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"> </span><br><span class="line"># Define your item pipelines here</span><br><span class="line">#</span><br><span class="line"># Don&#39;t forget to add your pipeline to the ITEM_PIPELINES setting</span><br><span class="line"># See: https:&#x2F;&#x2F;doc.scrapy.org&#x2F;en&#x2F;latest&#x2F;topics&#x2F;item-pipeline.html</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">class BaidustocksPipeline(object):</span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        return item</span><br><span class="line"> </span><br><span class="line">class BaidustocksInfoPipeline(object):</span><br><span class="line">    def open_spider(self, spider):</span><br><span class="line">        self.f &#x3D; open(&#39;BaiduStockInfo.txt&#39;, &#39;w&#39;)</span><br><span class="line"> </span><br><span class="line">    def close_spider(self, spider):</span><br><span class="line">        self.f.close()</span><br><span class="line"> </span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        try:</span><br><span class="line">            line &#x3D; str(dict(item)) + &#39;\n&#39;</span><br><span class="line">            self.f.write(line)</span><br><span class="line">        except:</span><br><span class="line">            pass</span><br><span class="line">        return item</span><br></pre></td></tr></table></figure>


</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/21/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%EF%BC%88%E7%AC%AC4%E5%91%A8%20%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6%20%E7%AC%AC%E5%8D%81%E4%B8%80%E5%8D%95%E5%85%83%20Scrapy%E7%88%AC%E8%99%AB%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%EF%BC%89/">Python网络爬虫与信息提取（第4周 网络爬虫框架 第十一单元 Scrapy爬虫基本使用）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-21</time><div class="content"><h1 id="Scrapy爬虫的第一个实例"><a href="#Scrapy爬虫的第一个实例" class="headerlink" title="Scrapy爬虫的第一个实例"></a>Scrapy爬虫的第一个实例</h1><p>演示HTML页面地址：     </p>
<p><a href="http://python123.io/ws/demo.html" target="_blank" rel="noopener">http://python123.io/ws/demo.html</a>    </p>
<p>文件名称：demo.html</p>
<p><strong>爬虫步骤：</strong>   </p>
<ol>
<li>建立一个Scrapy爬虫工程       </li>
</ol>
<p>在工程路径下打开cmd, 输入<code>scrapy stratproject python123demo</code>,定义一个名为python123demo的文件夹  </p>
<p><img src="https://i.loli.net/2020/06/21/bAQupzMg26taRKX.png" alt=""></p>
<p>随后打开路径，会发现已经建立好了一个文件夹   </p>
<p><img src="https://i.loli.net/2020/06/21/wH123tiZGexsd9b.png" alt=""></p>
<p>生成的工程路径： </p>
<p><img src="https://i.loli.net/2020/06/21/4kyHIgZ78iR2vfd.png" alt=""></p>
<p><img src="https://i.loli.net/2020/06/21/uOcdYtlCspKI1Qh.png" alt=""></p>
<ol start="2">
<li>在工程中产生一个Scrapy爬虫     </li>
</ol>
<p>进入python123demo,cmd输入<code>scrapy genspider demo python123.io</code>产生名为demo的spider</p>
<p><img src="https://i.loli.net/2020/06/21/JDwHBoA8zhUExbv.png" alt="生成一条名称为demo的spider"></p>
<p>生成爬虫的代码内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">#demo.py文件</span><br><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class DemoSpider(scrapy.Spider):</span><br><span class="line">    name &#x3D; &#39;demo&#39;   #名称</span><br><span class="line">    allowed_domains &#x3D; [&#39;python123.io&#39;]  #只能爬虫这个域名以下的链接</span><br><span class="line">    start_urls &#x3D; [&#39;http:&#x2F;&#x2F;python123.io&#x2F;&#39;]   #爬取页面的初始页面</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>

<p><strong>parse()用于处理响应，解析内容形成字典，发现新的URL爬取请求。</strong></p>
<ol start="3">
<li>配置产生的spider爬虫    </li>
</ol>
<p>对上述spider进行配置：  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class DemoSpider(scrapy.Spider):</span><br><span class="line">    name &#x3D; &#39;demo&#39;</span><br><span class="line">    allowed_domains &#x3D; [&#39;python123.io&#39;]</span><br><span class="line">    start_urls &#x3D; [&#39;http:&#x2F;&#x2F;python123.io&#x2F;ws&#x2F;demo.html&#39;]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        fname &#x3D; response.url.split(&#39;&#x2F;&#39;)[-1] #存储到本地的response文件名称</span><br><span class="line">        with open(fname, &#39;wb&#39;) as f :</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        self.log(&quot;Saved file %s.&quot; % name)</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>运行爬虫，获取网页    </li>
</ol>
<p>cmd内输入<code>scrapy crawl demo</code>，捕获页面存储在html文件中</p>
<p><img src="https://i.loli.net/2020/06/21/zI2sELjWvt3frpF.png" alt=""></p>
<h2 id="yield关键字的使用"><a href="#yield关键字的使用" class="headerlink" title="yield关键字的使用"></a>yield关键字的使用</h2><p>生成器是一个不断产生值的函数。      </p>
<p>包含yield语句的函数是一个生成器。     </p>
<p>生成器每次产生一个值(yield语句)，函数被冻结，被唤醒后再产生一个值。</p>
<p><strong><em>生成器写法：</em></strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def gen(n) :</span><br><span class="line">    for i in range(n) :</span><br><span class="line">        yield i ** 2</span><br><span class="line"></span><br><span class="line">for i in gen(5):</span><br><span class="line">    print(i, &#39; &#39;, end&#x3D;&#39;&#39;)</span><br></pre></td></tr></table></figure>

<p><strong><em>普通写法：</em></strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def square(n) :</span><br><span class="line">    ls &#x3D; [i**2 for i in range(n)]</span><br><span class="line">    return ls</span><br><span class="line"></span><br><span class="line">for i in square(5):</span><br><span class="line">    print(i, &#39; &#39;, end&#x3D;&#39;&#39;)</span><br></pre></td></tr></table></figure>

<p>生成器：<br>更节省存储空间<br>响应更迅速<br>使用更灵活   </p>
<h1 id="Scrapy爬虫的基本使用"><a href="#Scrapy爬虫的基本使用" class="headerlink" title="Scrapy爬虫的基本使用"></a>Scrapy爬虫的基本使用</h1><p><strong>Scrapy爬虫的使用步骤</strong></p>
<p>步骤一：创建一个工程和Spider模板     </p>
<p>步骤二：编写Spider    </p>
<p>步骤三：编写Item Pipeline     </p>
<p>步骤四：优化配置策略      </p>
<p><strong>Scrapy爬虫的数据类型</strong></p>
<p>Request类：表示一个HTTP请求，由Spider生成，由Downloader执行。    </p>
<table>
<thead>
<tr>
<th align="center">属性或方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">.url</td>
<td align="center">Request对应的请求URL地址</td>
</tr>
<tr>
<td align="center">.method</td>
<td align="center">对应的请求方法，’GET’ ‘POST’等</td>
</tr>
<tr>
<td align="center">.headers</td>
<td align="center">字典类型风格的请求头</td>
</tr>
<tr>
<td align="center">.body</td>
<td align="center">请求内容主体，字符串类型</td>
</tr>
<tr>
<td align="center">.meta</td>
<td align="center">用户添加的扩展信息，在Scrapy内部模块间传递信息使用</td>
</tr>
<tr>
<td align="center">.copy()</td>
<td align="center">复制该请求</td>
</tr>
</tbody></table>
<p>Response类：表示一个HTTP响应，由Downloader生成，由Spider处理</p>
<table>
<thead>
<tr>
<th align="center">属性或方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">.url</td>
<td align="center">Response对应的URL地址</td>
</tr>
<tr>
<td align="center">.status</td>
<td align="center">HTTP状态码，默认是200</td>
</tr>
<tr>
<td align="center">.headers</td>
<td align="center">Response对应的头部信息</td>
</tr>
<tr>
<td align="center">.body</td>
<td align="center">Response对应的内容信息，字符串类型</td>
</tr>
<tr>
<td align="center">.flags</td>
<td align="center">一组标记</td>
</tr>
<tr>
<td align="center">.request</td>
<td align="center">产生Response类型对应的Request对象</td>
</tr>
<tr>
<td align="center">.copy()</td>
<td align="center">复制该响应</td>
</tr>
</tbody></table>
<p>Item类：表示从一个HTML页面中提取的信息内容，由Spider生成，由Item Pipeline处理<br>类似于字典，可用字典类型使用      </p>
<p><strong>CSS Selector的基本使用：</strong></p>
<p><img src="https://i.loli.net/2020/06/21/fjLIdzmBqwYDb65.png" alt=""></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/21/%E4%BB%8E%E9%94%AE%E7%9B%98%E8%BE%93%E5%85%A5%E5%B9%B4%E6%9C%88%E6%97%A5%EF%BC%8C%E8%AE%A1%E7%AE%97%E6%98%AF%E8%BF%99%E4%B8%80%E5%B9%B4%E4%B8%AD%E7%9A%84%E7%AC%AC%E5%87%A0%E5%A4%A9/">从键盘输入年月日，计算是这一年中的第几天</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-21</time><div class="content"><p>这个问题是我同学给我的期末Python模拟题里面的一道，最开始我是试着用判断是否闰年，分30天的月份和31天的月份。      </p>
<p>结果代码越写越长，显然是不太合适的。       </p>
<p>下面的是我用最初的方法写的代码：     </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">months_days30 &#x3D; [4,6,9,11]</span><br><span class="line">months_days31 &#x3D; [1,3,5,7,8,10,12]</span><br><span class="line">month_Feb &#x3D; 2 #区分不同的月份对应的天数</span><br><span class="line"></span><br><span class="line">def isleapyear(year) : #判断是否为闰年</span><br><span class="line">    if year % 4 &#x3D;&#x3D; 0 :</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br><span class="line"></span><br><span class="line">def main(): #计算天数</span><br><span class="line">    year &#x3D; eval(input(&quot;请输入年份：&quot;))</span><br><span class="line">    month &#x3D; eval(input(&quot;请输入月份：&quot;))</span><br><span class="line">    day &#x3D; eval(input(&quot;请输入年份：&quot;))</span><br><span class="line">    num_day31 &#x3D; 0</span><br><span class="line">    num_day30 &#x3D; 0</span><br><span class="line"></span><br><span class="line">    if month &#x3D;&#x3D; 1 :</span><br><span class="line">        print(str(day))</span><br><span class="line">    if month &#x3D;&#x3D; 2 :</span><br><span class="line">        print(str(day+31))</span><br><span class="line">    for d30 in months_days30 :</span><br><span class="line">        if d30 &lt; month :</span><br><span class="line">            num_day30 +&#x3D; 1</span><br><span class="line">        else:</span><br><span class="line">            break</span><br><span class="line">    for d31 in months_days31 :</span><br><span class="line">        if d31 &lt; month :</span><br><span class="line">            num_day31 +&#x3D; 1</span><br><span class="line">        else:</span><br><span class="line">            break</span><br><span class="line">    if isleapyear(year) :</span><br><span class="line">        print(num_day30 * 30 + num_day31 * 31 + 29 + day)</span><br><span class="line">    else :</span><br><span class="line">        print(num_day30 * 30 + num_day31 * 31 + 28 + day)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

<p>后来又翻了一下嵩天的《Python语言程序设计基础》，复习了一下time库和datetime库，发现几行代码就可以解决。    </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">date_input &#x3D; input(&quot;请输入日期(年-月-日）：&quot;)</span><br><span class="line">t &#x3D; time.strptime(date_input, &#39;%Y-%m-%d&#39;)</span><br><span class="line">print(time.strftime(&#39;%j&#39;,t))</span><br></pre></td></tr></table></figure>

<p>具体方法：   </p>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">%a</td>
<td align="center">英文星期简写</td>
</tr>
<tr>
<td align="center">%A</td>
<td align="center">英文星期的完全</td>
</tr>
<tr>
<td align="center">%b</td>
<td align="center">英文月份的简写</td>
</tr>
<tr>
<td align="center">%B</td>
<td align="center">英文月份的完全</td>
</tr>
<tr>
<td align="center">%c</td>
<td align="center">显示本地日期时间</td>
</tr>
<tr>
<td align="center">%d</td>
<td align="center">日期，取1-31</td>
</tr>
<tr>
<td align="center">%H</td>
<td align="center">小时， 0-23</td>
</tr>
<tr>
<td align="center">%I</td>
<td align="center">小时， 0-12</td>
</tr>
<tr>
<td align="center">%m</td>
<td align="center">月， 01 -12</td>
</tr>
<tr>
<td align="center">%M</td>
<td align="center">分钟，1-59</td>
</tr>
<tr>
<td align="center">%j</td>
<td align="center">年中当天的天数</td>
</tr>
<tr>
<td align="center">%w</td>
<td align="center">显示今天是星期几</td>
</tr>
<tr>
<td align="center">%W</td>
<td align="center">第几周</td>
</tr>
<tr>
<td align="center">%x</td>
<td align="center">当天日期</td>
</tr>
<tr>
<td align="center">%X</td>
<td align="center">本地的当天时间</td>
</tr>
<tr>
<td align="center">%y</td>
<td align="center">年份 00-99间</td>
</tr>
<tr>
<td align="center">%Y</td>
<td align="center">年份的完整拼写</td>
</tr>
</tbody></table>
<p>所以在这个实例中，直接用<code>%j</code>即可显示日期对应的当年天数。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/20/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%EF%BC%88%E7%AC%AC4%E5%91%A8%20%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6%20%E7%AC%AC%E5%8D%81%E5%8D%95%E5%85%83%20Scrapy%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6%EF%BC%89/">Python网络爬虫与信息提取（第4周 网络爬虫框架 第十单元 Scrapy爬虫框架）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-20</time><div class="content"><h1 id="Scrapy爬虫框架介绍"><a href="#Scrapy爬虫框架介绍" class="headerlink" title="Scrapy爬虫框架介绍"></a>Scrapy爬虫框架介绍</h1><h2 id="Scrapy的安装"><a href="#Scrapy的安装" class="headerlink" title="Scrapy的安装"></a>Scrapy的安装</h2><p>命令行输入<code>pip install Scrapy</code>       </p>
<p>安装后小测：执行<code>scrapy -h</code>     </p>
<p>安装的过程中可能会出现失败的情况，报错显示<code>error:MicrosoftVisual C++ 14.0 is required</code>   </p>
<p><strong>解决办法：</strong><br>根据Python版本和系统位数选择对应的Twisted模块(<a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/" target="_blank" rel="noopener">点击此处下载</a>)，例如我的Python是3.8，系统位数为64位，所以选择</p>
<p><img src="https://i.loli.net/2020/06/20/rL13TsQMgJwFIjA.png" alt=""></p>
<p>将文件下载到Python/Scripts文件夹，cd到此文件夹内输入<code>pip install Twisted-20.3.0-cp38-cp38-win_amd64.whl</code>      </p>
<p>安装成功后再输入<code>pip install scrapy</code>即可成功    </p>
<p>scrapy不单单是一个库，而是一个爬虫框架      </p>
<p><strong>爬虫框架：</strong>是实现爬虫功能的一个软件结构和功能组件集合      </p>
<h2 id="Scrapy爬虫框架结构"><a href="#Scrapy爬虫框架结构" class="headerlink" title="Scrapy爬虫框架结构"></a>Scrapy爬虫框架结构</h2><p><strong>5+2结构和3条数据流：</strong></p>
<p><img src="https://i.loli.net/2020/06/20/UGyuikEcmS3aNzr.png" alt="5+2结构和3条数据流"></p>
<p>结构中，用户需要编写配置的是模块是<strong>SPIDERS(入口)</strong>和<strong>ITEM PIPELINES(出口)</strong></p>
<h1 id="Scrapy爬虫框架解析"><a href="#Scrapy爬虫框架解析" class="headerlink" title="Scrapy爬虫框架解析"></a>Scrapy爬虫框架解析</h1><p><strong>Engine：</strong>控制所有模块之间的数据流/根据条件出发事件，不需要用户修改       </p>
<p><strong>Downloader：</strong>跟去请求下载网页，不需要用户修改     </p>
<p><strong>Scheduler:</strong>对所有爬取请求进行调度管理，不需要用户修改     </p>
<p><strong>Downloader Middleware:</strong>实施上述三组模块站之间进行用户可配置的控制。修改、丢弃、新增请求或相应。     </p>
<p><strong>Spider:</strong>解析Downloader返回的响应(Response)/产生爬取项(scraped item)/产生额外的爬取请求(Request)       </p>
<p><strong>Item Pipelines:</strong>以流水线方式处理Spider产生的爬取项/由一组操作顺序组成，类似流水线，每个操作是一个Item Pipeline类型/可能操作包括：清理、检验和查重爬取项中的HTML数据，将数据存储到数据库     </p>
<p><strong>Spider Middleware:</strong>对请求和爬取项的再处理。修改、丢弃、新增请求或爬取项。       </p>
<h1 id="Requests库和Scrapy框架的比较"><a href="#Requests库和Scrapy框架的比较" class="headerlink" title="Requests库和Scrapy框架的比较"></a>Requests库和Scrapy框架的比较</h1><p><strong>相同点：</strong>       </p>
<p>两者都可以进行页面请求和爬取，Python爬虫的两个重要技术路线        </p>
<p>两者可用性都好，文档丰富，入门简单       </p>
<p>两者都没有处理js、提交表单、应对验证码等功能(可扩展)        </p>
<p><strong>不同点:</strong>    </p>
<table>
<thead>
<tr>
<th align="center">requests</th>
<th align="center">Serapy</th>
</tr>
</thead>
<tbody><tr>
<td align="center">页面级爬虫</td>
<td align="center">网站级爬虫</td>
</tr>
<tr>
<td align="center">功能库</td>
<td align="center">框架</td>
</tr>
<tr>
<td align="center">并发性考虑不足，性能较差</td>
<td align="center">并发性好，性能较高</td>
</tr>
<tr>
<td align="center">重点在于页面下载</td>
<td align="center">重点在于爬虫结构</td>
</tr>
<tr>
<td align="center">定制灵活</td>
<td align="center">一般定制灵活，深度定制困难</td>
</tr>
<tr>
<td align="center">上手十分简单</td>
<td align="center">入门稍难</td>
</tr>
</tbody></table>
<p><strong><em>对于非常小的需求，用Requests库。</em></strong>      </p>
<p><strong><em>对于不太小的需求，用Scrapy框架</em></strong></p>
<h1 id="Scrapy爬虫的常用指令"><a href="#Scrapy爬虫的常用指令" class="headerlink" title="Scrapy爬虫的常用指令"></a>Scrapy爬虫的常用指令</h1><p>Scrapy是为持续运行设计的专业爬虫框架，提供操作的Scrapy命令行。  </p>
<p>cmd里输入<code>scrapy -h</code>即可打开Scrapy命令行      </p>
<p>Scrapy命令行格式：    </p>
<blockquote>
<p>scrapy<command>[options][args]     </p>
</blockquote>
<p><strong>Scrapy常用命令</strong></p>
<table>
<thead>
<tr>
<th align="center">命令</th>
<th align="center">说明</th>
<th align="center">格式</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>startproject</strong></td>
<td align="center">创建一个新工程</td>
<td align="center">scrapy startproject<name>[dir]</td>
</tr>
<tr>
<td align="center"><strong>genspider</strong></td>
<td align="center">创建一个爬虫</td>
<td align="center">scrapy genspider [options]<name><domain></td>
</tr>
<tr>
<td align="center">settings</td>
<td align="center">获得爬虫配置信息</td>
<td align="center">scrapy settings [options]</td>
</tr>
<tr>
<td align="center"><strong>crawl</strong></td>
<td align="center">运行一个爬虫</td>
<td align="center">scrapy crawl <spider></td>
</tr>
<tr>
<td align="center">list</td>
<td align="center">列出工程中所有爬虫</td>
<td align="center">scrapy list</td>
</tr>
<tr>
<td align="center">shell</td>
<td align="center">启动URL调试命令行</td>
<td align="center">scrapy shell [url]</td>
</tr>
</tbody></table>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/18/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%EF%BC%88%E7%AC%AC3%E5%91%A8%20%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%20%E7%AC%AC%E5%85%AB%E4%B9%9D%E5%8D%95%E5%85%83%20%E5%AE%9E%E4%BE%8B%EF%BC%89/">Python网络爬虫与信息提取（第3周 网络爬虫实战 第八九单元 实例）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-18</time><div class="content"><h1 id="淘宝商品比价定向爬虫实例"><a href="#淘宝商品比价定向爬虫实例" class="headerlink" title="淘宝商品比价定向爬虫实例"></a>淘宝商品比价定向爬虫实例</h1><hr>
<p><strong>流程图：</strong></p>
<p><img src="https://i.loli.net/2020/06/18/2Amz9ujKZkIwlNd.png" alt="流程图"></p>
<p><strong>代码编写：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def getHTMLText(url):</span><br><span class="line">    try:</span><br><span class="line">        r &#x3D; requests.get(url, timeout&#x3D;30)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding &#x3D; r.apparent_encoding</span><br><span class="line">        return r.text</span><br><span class="line">    except:</span><br><span class="line">        return &quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parsePage(ilt, html):</span><br><span class="line">    try:</span><br><span class="line">        plt &#x3D; re.findall(r&#39;\&quot;view_price\&quot;\:\&quot;[\d\.]*\&quot;&#39;, html)</span><br><span class="line">        tlt &#x3D; re.findall(r&#39;\&quot;raw_title\&quot;\:\&quot;.*?\&quot;&#39;, html)</span><br><span class="line">        for i in range(len(plt)):</span><br><span class="line">            price &#x3D; eval(plt[i].split(&#39;:&#39;)[1])</span><br><span class="line">            title &#x3D; eval(tlt[i].split(&#39;:&#39;)[1])</span><br><span class="line">            ilt.append([price, title])</span><br><span class="line">    except:</span><br><span class="line">        print(&quot;&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def printGoodsList(ilt):</span><br><span class="line">    tplt &#x3D; &quot;&#123;:4&#125;\t&#123;:8&#125;\t&#123;:16&#125;&quot;</span><br><span class="line">    print(tplt.format(&quot;序号&quot;, &quot;价格&quot;, &quot;商品名称&quot;))</span><br><span class="line">    count &#x3D; 0</span><br><span class="line">    for g in ilt:</span><br><span class="line">        count &#x3D; count + 1</span><br><span class="line">        print(tplt.format(count, g[0], g[1]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    goods &#x3D; &#39;书包&#39;</span><br><span class="line">    depth &#x3D; 3</span><br><span class="line">    start_url &#x3D; &#39;https:&#x2F;&#x2F;s.taobao.com&#x2F;search?q&#x3D;&#39; + goods</span><br><span class="line">    infoList &#x3D; []</span><br><span class="line">    for i in range(depth):</span><br><span class="line">        try:</span><br><span class="line">            url &#x3D; start_url + &#39;&amp;s&#x3D;&#39; + str(44 * i)</span><br><span class="line">            html &#x3D; getHTMLText(url)</span><br><span class="line">            parsePage(infoList, html)</span><br><span class="line">        except:</span><br><span class="line">            continue</span><br><span class="line">    printGoodsList(infoList)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

<h1 id="股票数据定向爬虫实例"><a href="#股票数据定向爬虫实例" class="headerlink" title="股票数据定向爬虫实例"></a>股票数据定向爬虫实例</h1><hr>
<p>候选数据网站选择：<a href="http://finance.sina.com.cn/stock/" target="_blank" rel="noopener">新浪股票</a>、<a href="https://gupiao.baidu.com/stock/" target="_blank" rel="noopener">百度股票</a>、<a href="http://quote.eastmoney.com/center/gridlist.html#hs_a_board" target="_blank" rel="noopener">东方财富网</a><br><strong>数据网站选择原则：</strong><br>股票信息静态存在于HTML页面中，非js代码生成，没有Robots协议限制。</p>
<p><strong>流程图：</strong></p>
<p><img src="https://i.loli.net/2020/06/19/DvXQAj4ikfZswap.png" alt="流程图"></p>
<p><strong>代码编写：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">#CrawBaiduStocksB.py</span><br><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import traceback</span><br><span class="line">import re</span><br><span class="line"> </span><br><span class="line">def getHTMLText(url, code&#x3D;&quot;utf-8&quot;):</span><br><span class="line">    try:</span><br><span class="line">        r &#x3D; requests.get(url)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding &#x3D; code</span><br><span class="line">        return r.text</span><br><span class="line">    except:</span><br><span class="line">        return &quot;&quot;</span><br><span class="line"> </span><br><span class="line">def getStockList(lst, stockURL):</span><br><span class="line">    html &#x3D; getHTMLText(stockURL, &quot;GB2312&quot;)</span><br><span class="line">    soup &#x3D; BeautifulSoup(html, &#39;html.parser&#39;) </span><br><span class="line">    a &#x3D; soup.find_all(&#39;a&#39;)</span><br><span class="line">    for i in a:</span><br><span class="line">        try:</span><br><span class="line">            href &#x3D; i.attrs[&#39;href&#39;]</span><br><span class="line">            lst.append(re.findall(r&quot;[s][hz]\d&#123;6&#125;&quot;, href)[0])</span><br><span class="line">        except:</span><br><span class="line">            continue</span><br><span class="line"> </span><br><span class="line">def getStockInfo(lst, stockURL, fpath):</span><br><span class="line">    count &#x3D; 0</span><br><span class="line">    for stock in lst:</span><br><span class="line">        url &#x3D; stockURL + stock + &quot;.html&quot;</span><br><span class="line">        html &#x3D; getHTMLText(url)</span><br><span class="line">        try:</span><br><span class="line">            if html&#x3D;&#x3D;&quot;&quot;:</span><br><span class="line">                continue</span><br><span class="line">            infoDict &#x3D; &#123;&#125;</span><br><span class="line">            soup &#x3D; BeautifulSoup(html, &#39;html.parser&#39;)</span><br><span class="line">            stockInfo &#x3D; soup.find(&#39;div&#39;,attrs&#x3D;&#123;&#39;class&#39;:&#39;stock-bets&#39;&#125;)</span><br><span class="line"> </span><br><span class="line">            name &#x3D; stockInfo.find_all(attrs&#x3D;&#123;&#39;class&#39;:&#39;bets-name&#39;&#125;)[0]</span><br><span class="line">            infoDict.update(&#123;&#39;股票名称&#39;: name.text.split()[0]&#125;)</span><br><span class="line">             </span><br><span class="line">            keyList &#x3D; stockInfo.find_all(&#39;dt&#39;)</span><br><span class="line">            valueList &#x3D; stockInfo.find_all(&#39;dd&#39;)</span><br><span class="line">            for i in range(len(keyList)):</span><br><span class="line">                key &#x3D; keyList[i].text</span><br><span class="line">                val &#x3D; valueList[i].text</span><br><span class="line">                infoDict[key] &#x3D; val</span><br><span class="line">             </span><br><span class="line">            with open(fpath, &#39;a&#39;, encoding&#x3D;&#39;utf-8&#39;) as f:</span><br><span class="line">                f.write( str(infoDict) + &#39;\n&#39; )</span><br><span class="line">                count &#x3D; count + 1</span><br><span class="line">                print(&quot;\r当前进度: &#123;:.2f&#125;%&quot;.format(count*100&#x2F;len(lst)),end&#x3D;&quot;&quot;)</span><br><span class="line">        except:</span><br><span class="line">            count &#x3D; count + 1</span><br><span class="line">            print(&quot;\r当前进度: &#123;:.2f&#125;%&quot;.format(count*100&#x2F;len(lst)),end&#x3D;&quot;&quot;)</span><br><span class="line">            continue</span><br><span class="line"> </span><br><span class="line">def main():</span><br><span class="line">    stock_list_url &#x3D; &#39;http:&#x2F;&#x2F;quote.eastmoney.com&#x2F;center&#x2F;gridlist.html#hs_a_board&#39;</span><br><span class="line">    stock_info_url &#x3D; &#39;https:&#x2F;&#x2F;gupiao.baidu.com&#x2F;stock&#x2F;&#39;</span><br><span class="line">    output_file &#x3D; &#39;D:&#x2F;BaiduStockInfo.txt&#39;</span><br><span class="line">    slist&#x3D;[]</span><br><span class="line">    getStockList(slist, stock_list_url)</span><br><span class="line">    getStockInfo(slist, stock_info_url, output_file)</span><br><span class="line"> </span><br><span class="line">main()</span><br></pre></td></tr></table></figure></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/17/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%EF%BC%88%E7%AC%AC3%E5%91%A8%20%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%20%E5%8D%95%E5%85%83%E4%B8%83%20Re%E5%BA%93%E5%85%A5%E9%97%A8%EF%BC%89/">Python网络爬虫与信息提取（第3周 网络爬虫实战 单元七 Re库入门）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-17</time><div class="content"><h1 id="正则表达式的概念"><a href="#正则表达式的概念" class="headerlink" title="正则表达式的概念"></a>正则表达式的概念</h1><p>Regular expression–Re<br><strong>·通用的字符串表达框架<br>·简洁表达一组字符串的表达式<br>·针对字符串表达“简洁”和“特征”思想的工具<br>·判断某字符串的特征归属</strong>        </p>
<h1 id="正则表达式的语法"><a href="#正则表达式的语法" class="headerlink" title="正则表达式的语法"></a>正则表达式的语法</h1><p>eg:<strong>P(Y|YT|YTH|YTHO)?N</strong><br>正则表达式由字符和操作符构成       </p>
<p><strong>正则表达式常用的操作符</strong></p>
<table>
<thead>
<tr>
<th align="center">操作符</th>
<th align="center">说明</th>
<th align="center">实例</th>
</tr>
</thead>
<tbody><tr>
<td align="center">.</td>
<td align="center">表示任何单个字符</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">[ ]</td>
<td align="center">字符集，对单个字符给出取值范围</td>
<td align="center">[abe]表示a、 b、c, [a-z]表示a到z单个字符</td>
</tr>
<tr>
<td align="center">[^ ]</td>
<td align="center">非字符集，对单个字符给出排除范围</td>
<td align="center">[^abc]表示非a或b或c的单个字符</td>
</tr>
<tr>
<td align="center">*</td>
<td align="center">前一个字符0次或无限次扩展</td>
<td align="center">abc*表示ab、abc、abce、abecc等</td>
</tr>
<tr>
<td align="center">+</td>
<td align="center">前一个字符1次或无限次扩展</td>
<td align="center">abc+表示abc、abcc、 abccc等</td>
</tr>
<tr>
<td align="center">?</td>
<td align="center">前一个字符0次或1次扩展</td>
<td align="center">abc?表示ab、abc</td>
</tr>
<tr>
<td align="center">`</td>
<td align="center">`</td>
<td align="center">左右表达式任意一个</td>
</tr>
<tr>
<td align="center"><code>{m}</code></td>
<td align="center">扩展前一个字符m次</td>
<td align="center">ab{2}c表示abbc</td>
</tr>
<tr>
<td align="center"><code>{m,n}</code></td>
<td align="center">扩展前一个字符m至n次(含n)</td>
<td align="center">ab{1,2}c表示abc、abbc</td>
</tr>
<tr>
<td align="center">^</td>
<td align="center">匹配字符串开头</td>
<td align="center">^abc表示abc且在一个字符串的开头</td>
</tr>
<tr>
<td align="center">$</td>
<td align="center">匹配字符串结尾</td>
<td align="center">abc$表示abc且在一个字符串的结尾</td>
</tr>
<tr>
<td align="center">()</td>
<td align="center">分组标记，内部只能使用`</td>
<td align="center">`操作符</td>
</tr>
<tr>
<td align="center">\d</td>
<td align="center">数字，等价于[0-9]</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">\w</td>
<td align="center">单词字符，等价于[A-Za-z0-9_]</td>
<td align="center"></td>
</tr>
</tbody></table>
<p><strong>正则表达式语法实例</strong></p>
<table>
<thead>
<tr>
<th align="center">正则表达式</th>
<th align="center">对应字符串</th>
</tr>
</thead>
<tbody><tr>
<td align="center">`P(Y</td>
<td align="center">YT</td>
</tr>
<tr>
<td align="center">PYTHON+</td>
<td align="center">‘PYTHON’ ‘PYTHONN’ ‘PYTHONNN’…</td>
</tr>
<tr>
<td align="center">PY[TH]ON</td>
<td align="center">‘PYTON’ ‘PYHON’</td>
</tr>
<tr>
<td align="center">PY[^TH]?ON</td>
<td align="center">‘PYON’ ‘PTaon’ ‘PYbON’ ‘PYcON’…</td>
</tr>
<tr>
<td align="center">PY{:3}N</td>
<td align="center">‘PN’ ‘PYN’ ‘PYYN’ ‘PYYYN’</td>
</tr>
</tbody></table>
<p><strong>经典正则表达式实例</strong><br>^[A-Za-z]+$&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;由26个字母组成的字符串<br>^[A-Za-z0-9]+$&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;由26个字母和数字组成的字符串<br>^-?\d+$&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&emsp;&ensp;整数形式的字符串<br><code>^[0-9]*[1-9][0-9]*$</code>&ensp;&ensp;&ensp;&ensp;&ensp;正整数形式的字符串<br>[1-9]\d{5}&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;中国境内邮政编码，6位<br>[\u4e00-\u9fa5]&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;匹配中文字符<br>\d{3}-\d{8}|\d{4}-\d{7}&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;国内电话号码，010-68913536</p>
<h1 id="Re库的基本使用"><a href="#Re库的基本使用" class="headerlink" title="Re库的基本使用"></a>Re库的基本使用</h1><p>正则表达式的表达类型<br><strong>·raw string类型(原生字符串)<br>·sting类型，较繁琐</strong>      </p>
<h2 id="Re库主要功能函数"><a href="#Re库主要功能函数" class="headerlink" title="Re库主要功能函数"></a>Re库主要功能函数</h2><table>
<thead>
<tr>
<th align="center">函数</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">re.search()</td>
<td align="center">在一个字符串中搜索匹配正则表达式的第一个位置，返回match对象</td>
</tr>
<tr>
<td align="center">re.match()</td>
<td align="center">从一个字符串的开始位置起匹配正则表达式，返回match对象</td>
</tr>
<tr>
<td align="center">re.findall()</td>
<td align="center">搜索字符串，以列表类型返回全部能匹配的子串</td>
</tr>
<tr>
<td align="center">re.split()</td>
<td align="center">将一个字符串按照正则表达式匹配结果进行分割，返回列表类型</td>
</tr>
<tr>
<td align="center">re.finditer()</td>
<td align="center">搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是match对象</td>
</tr>
<tr>
<td align="center">re.sub()</td>
<td align="center">在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串</td>
</tr>
</tbody></table>
<p><strong>re.search(parttern,string,flags=0)</strong><br>※在一个字符串中搜索匹配正则表达式的第一个位置，返回match对象。<br>pattern:正则表达式的字符串或原生字符串表示<br>strings:待匹配字符串<br>flags:正则表达式使用时的控制标记<br>flags常用控制标记：    </p>
<table>
<thead>
<tr>
<th align="center">常用标记</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">re.I(re.IGNORECASE)</td>
<td align="center">忽略正则表达式的大小写，[A-Z]能够匹配小写字符</td>
</tr>
<tr>
<td align="center">re.M(re.MULTLINE)</td>
<td align="center">正则表达式中的^操作符能够将给定字符串的每行当作匹配开始</td>
</tr>
<tr>
<td align="center">re.S(re.DOTALL)</td>
<td align="center">正则表达式中的.操作符能够匹配所有字符，默认匹配除换行外的所有字符</td>
</tr>
</tbody></table>
<p><strong>re.match(pattern,string,flags=0)</strong><br>※从一个字符串的开始位置起匹配正则表达式，返回match对象。<br>pattern:正则表达式的字符串或原生字符串表示<br>string:待匹配字符串<br>flags:正则表达式使用时的控制标记     </p>
<p><strong>re.findall(pattern,string,flags=0)</strong><br>※搜索字符串，以列表类型返回全部能匹配的子串。<br>pattern:正则表达式的字符串或原生字符串表示<br>string;待匹配字符串<br>flags:正则表达式使用时的控制标记     </p>
<p><strong>re.split(pattern, string, maxsplit=0, flags=0)</strong><br>※将一个字符串按照正则表达式匹配结果进行分割，返回列表类型。<br>pattern:正则表达式的字符串或原生字符串表示<br>string;待匹配字符串<br>maxsplit:最大分割数，剩余部分作为最后一个元素输出<br>flags:正则表达式使用时的控制标记     </p>
<p><strong>re.finditer(pattern,string,flags=0)</strong><br>※搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是match对象。<br>pattern:正则表达式的字符串或原生字符串表示<br>string:待匹配字符串<br>flags:正则表达式使用时的控制标记     </p>
<p><strong>re.sub(pattern, repl, string, count=0, flags=0)</strong><br>※在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串。<br>pattern:正则表达式的字符串或原生字符串表示<br>repl:替换匹配字符串的字符串<br>string:待匹配字符串<br>count:匹配的最大替换次数<br>flags:正则表达式使用时的控制标记     </p>
<p><strong>regex = re.compile(pattern, flags=0)</strong><br>※将正则表达式的字符串形式编译成正则表达式对象<br>pattern:正则表达式的字符串或原生字符串表示<br>flags:正则表达式使用时的控制标记     </p>
<h2 id="Re库的Match对象"><a href="#Re库的Match对象" class="headerlink" title="Re库的Match对象"></a>Re库的Match对象</h2><p><strong>Match对象的属性</strong>  </p>
<table>
<thead>
<tr>
<th align="center">属性</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">.string</td>
<td align="center">待匹配的文本</td>
</tr>
<tr>
<td align="center">.re</td>
<td align="center">匹配时使用的pattern对象(正则表达式)</td>
</tr>
<tr>
<td align="center">.pos</td>
<td align="center">正则表达式搜索文本的开始位置</td>
</tr>
<tr>
<td align="center">.endpos</td>
<td align="center">正则表达式搜索文本的结束位置</td>
</tr>
</tbody></table>
<p><strong>Match对象的方法</strong></p>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">.group(0)</td>
<td align="center">获得匹配后的字符串</td>
</tr>
<tr>
<td align="center">.start()</td>
<td align="center">匹配字符串在原始字符串的开始位置</td>
</tr>
<tr>
<td align="center">.end()</td>
<td align="center">匹配字符串在原始字符串的结束位置</td>
</tr>
<tr>
<td align="center">.span()</td>
<td align="center">返回(.start(),.end())</td>
</tr>
</tbody></table>
<h2 id="Re库的贪婪匹配和最小匹配"><a href="#Re库的贪婪匹配和最小匹配" class="headerlink" title="Re库的贪婪匹配和最小匹配"></a>Re库的贪婪匹配和最小匹配</h2><p><strong>Re库默认采用贪婪匹配，即输出匹配最长的字符串</strong>     </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">match &#x3D; re.search(r&#39;PY.*N&#39;, &#39;PYANBNCNDN&#39;)</span><br><span class="line">print(match.group(0))</span><br></pre></td></tr></table></figure>
<p>输出：<code>PYANBNCNDN</code></p>
<p><strong>若要输出最小匹配字符串：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">match &#x3D; re.search(r&#39;PY.*?N&#39;, &#39;PYANBNCNDN&#39;)</span><br><span class="line">print(match.group(0))</span><br></pre></td></tr></table></figure>
<p>输出：<code>PYAN</code></p>
<p><strong>最小匹配操作符</strong></p>
<table>
<thead>
<tr>
<th align="center">操作符</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">*?</td>
<td align="center">前一个字符0次或无限次扩展，最小匹配</td>
</tr>
<tr>
<td align="center">+?</td>
<td align="center">前一个字符1次或无限次扩展，最小匹配</td>
</tr>
<tr>
<td align="center">??</td>
<td align="center">前一个字符0次或1次扩展，最小匹配</td>
</tr>
<tr>
<td align="center"><code>{m,n}?</code></td>
<td align="center">扩展前一个字符m至n次(含n)，最小匹配</td>
</tr>
</tbody></table>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/16/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%EF%BC%88%E7%AC%AC2%E5%91%A8%20%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E6%8F%90%E5%8F%96%20%E5%8D%95%E5%85%83%E5%85%AD%20%E4%B8%AD%E5%9B%BD%E5%A4%A7%E5%AD%A6%E6%8E%92%E5%90%8D%E7%88%AC%E8%99%AB%EF%BC%89/">Python网络爬虫与信息提取（第2周 网络爬虫提取 单元六 中国大学排名爬虫）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-16</time><div class="content"><p><img src="https://i.loli.net/2020/06/22/ZTaXs6i9SwBAzQt.png" alt="程序流程图"></p>
<h1 id="定向爬虫实例"><a href="#定向爬虫实例" class="headerlink" title="定向爬虫实例"></a>定向爬虫实例</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import bs4</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line">def getHTMLText(url):</span><br><span class="line">    try:</span><br><span class="line">        r &#x3D; requests.get(url, timeout &#x3D; 30)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding &#x3D; r.apparent_encoding</span><br><span class="line">        return  r.text</span><br><span class="line">    except:</span><br><span class="line">        return &quot;&quot;</span><br><span class="line"></span><br><span class="line">def fillUnivList(ulist, html):</span><br><span class="line">    soup &#x3D; BeautifulSoup(html, &quot;html.parser&quot;)</span><br><span class="line">    for tr in soup.find(&#39;tbody&#39;).children:</span><br><span class="line">        if isinstance(tr, bs4.element.Tag):</span><br><span class="line">            tds &#x3D; tr(&#39;td&#39;)</span><br><span class="line">            ulist.append([tds[0].string, tds[1].string, tds[4].string])</span><br><span class="line"></span><br><span class="line">def printUnivList(ulist, num):</span><br><span class="line">    print(&quot;&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;&quot;.format(&quot;排名&quot;, &quot;学校名称&quot;, &quot;总分&quot;))</span><br><span class="line">    for i in range(num):</span><br><span class="line">        u &#x3D; ulist[i]</span><br><span class="line">        print(&quot;&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;&quot;.format(u[0], u[1], u[2]))</span><br><span class="line">    print(&quot;Suc&quot; + str(num))</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    unifo &#x3D; []</span><br><span class="line">    url &#x3D; &quot;http:&#x2F;&#x2F;www.zuihaodaxue.com&#x2F;zuihaodaxuepaiming2020.html&quot;</span><br><span class="line">    html &#x3D; getHTMLText(url)</span><br><span class="line">    fillUnivList(unifo, html)</span><br><span class="line">    printUnivList(unifo, 20)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

<p><strong>输出结果</strong></p>
<p><img src="https://i.loli.net/2020/06/16/bB91nZezTtF7Usd.png" alt="输出结果"></p>
<h1 id="定向爬虫实例优化"><a href="#定向爬虫实例优化" class="headerlink" title="定向爬虫实例优化"></a>定向爬虫实例优化</h1><p><strong>中文对齐问题的解决</strong>：采用中文字符的空格填充<code>chr(12288)</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">#旨在优化中文字符空格的问题</span><br><span class="line">import requests</span><br><span class="line">import bs4</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line">def getHTMLText(url):</span><br><span class="line">    try:</span><br><span class="line">        r &#x3D; requests.get(url, timeout &#x3D; 30)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding &#x3D; r.apparent_encoding</span><br><span class="line">        return  r.text</span><br><span class="line">    except:</span><br><span class="line">        return &quot;&quot;</span><br><span class="line"></span><br><span class="line">def fillUnivList(ulist, html):</span><br><span class="line">    soup &#x3D; BeautifulSoup(html, &quot;html.parser&quot;)</span><br><span class="line">    for tr in soup.find(&#39;tbody&#39;).children:</span><br><span class="line">        if isinstance(tr, bs4.element.Tag):</span><br><span class="line">            tds &#x3D; tr(&#39;td&#39;)</span><br><span class="line">            ulist.append([tds[0].string, tds[1].string, tds[4].string])</span><br><span class="line"></span><br><span class="line">def printUnivList(ulist, num):</span><br><span class="line">    tplt &#x3D; &quot;&#123;0:^10&#125;\t&#123;1:&#123;3&#125;^10&#125;\t&#123;2:^10&#125;&quot;</span><br><span class="line">    print(tplt.format(&quot;排名&quot;, &quot;学校名称&quot;, &quot;总分&quot;, chr(12288)))</span><br><span class="line">    for i in range(num):</span><br><span class="line">        u &#x3D; ulist[i]</span><br><span class="line">        print(tplt.format(u[0], u[1], u[2], chr(12288)))</span><br><span class="line">    print(&quot;Suc&quot; + str(num))</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    unifo &#x3D; []</span><br><span class="line">    url &#x3D; &quot;http:&#x2F;&#x2F;www.zuihaodaxue.com&#x2F;zuihaodaxuepaiming2020.html&quot;</span><br><span class="line">    html &#x3D; getHTMLText(url)</span><br><span class="line">    fillUnivList(unifo, html)</span><br><span class="line">    printUnivList(unifo, 20)</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

<p><strong>输出结果</strong></p>
<p><img src="https://i.loli.net/2020/06/16/l6EbVGoksfxhXza.png" alt="输出结果"></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/16/Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96%EF%BC%88%E7%AC%AC2%E5%91%A8%20%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E6%8F%90%E5%8F%96%20%E5%8D%95%E5%85%83%E4%BA%94%20%E4%BF%A1%E6%81%AF%E7%BB%84%E7%BB%87%E4%B8%8E%E6%8F%90%E5%8F%96%E6%96%B9%E6%B3%95%EF%BC%89/">Python网络爬虫与信息提取（第2周 网络爬虫提取 单元五 信息组织与提取方法）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-16</time><div class="content"><h1 id="信息标记的三种形式"><a href="#信息标记的三种形式" class="headerlink" title="信息标记的三种形式"></a>信息标记的三种形式</h1><h2 id="XML（eXtensible-Markup-Language）"><a href="#XML（eXtensible-Markup-Language）" class="headerlink" title="XML（eXtensible Markup Language）"></a>XML（eXtensible Markup Language）</h2><p>标签中含有内容时：<code>&lt;name&gt; ... &lt;/name&gt;</code>  </p>
<p>标签中不含内容时：<code>&lt;name/&gt;</code>     </p>
<p>注释：<code>&lt;!-- --&gt;</code></p>
<h2 id="JSON-JavaScript-Object-Notation"><a href="#JSON-JavaScript-Object-Notation" class="headerlink" title="JSON(JavaScript Object Notation)"></a>JSON(JavaScript Object Notation)</h2><p>“key” : “value”<br>“key” : [“value1”,”value2”]<br>“key” : {“subkey”:”subvalue”}<br>“key” : {<br>&ensp;&ensp;”name1” : “value1”<br>&ensp;&ensp;”name2” : “value2”<br>}   </p>
<h2 id="YAML"><a href="#YAML" class="headerlink" title="YAML"></a>YAML</h2><p><strong>无类型键值对</strong> key:name     </p>
<p><strong>通过缩进表达所属关系</strong>：<br>name :<br>&ensp;&ensp;newname :<br>&ensp;&ensp;oldname :     </p>
<p><strong>用-号表达并列关系</strong>：<br>name :<br>-name1<br>-name2      </p>
<p><strong>用|表示整块数据 #表示注释</strong>      </p>
<h1 id="三种信息标记形式的比较"><a href="#三种信息标记形式的比较" class="headerlink" title="三种信息标记形式的比较"></a>三种信息标记形式的比较</h1><p>XML Internet.上的信息交互与传递。<br>JSON 移动应用云端和节点的信息通信，无注释。<br>YAML 各类系统的配置文件，有注释易读。       </p>
<h1 id="信息提取的一般方法"><a href="#信息提取的一般方法" class="headerlink" title="信息提取的一般方法"></a>信息提取的一般方法</h1><h2 id="方法一-完整解析信息的标记形式，再提取关键信息。"><a href="#方法一-完整解析信息的标记形式，再提取关键信息。" class="headerlink" title="方法一:完整解析信息的标记形式，再提取关键信息。"></a>方法一:完整解析信息的标记形式，再提取关键信息。</h2><p>XML JSON YAML<br><strong>需要标记解析器</strong><br>例如: bs4库的标签树遍历<br>优点:信息解析准确<br>缺点:提取过程繁琐，速度慢。      </p>
<h2 id="方法二-无视标记形式，直接搜索关键信息。"><a href="#方法二-无视标记形式，直接搜索关键信息。" class="headerlink" title="方法二:无视标记形式，直接搜索关键信息。"></a>方法二:无视标记形式，直接搜索关键信息。</h2><p><strong>搜索</strong><br>对信息的文本查找函数即可。<br>优点:提取过程简洁，速度较快。<br>缺点:提取结果准确性与信息内容相关。      </p>
<h1 id="基于bs4库的HTML内容查找方法"><a href="#基于bs4库的HTML内容查找方法" class="headerlink" title="基于bs4库的HTML内容查找方法"></a>基于bs4库的HTML内容查找方法</h1><p><strong>&lt; &gt;.find_ all(name, attrs, recursive, string, **kwargs)</strong><br>返回一个列表类型，存储查找的结果。<br><strong>name</strong>:对标签名称的检索字符串。<br><strong>attrs</strong>:对标签属性值的检索字符串，可标注属性检索。<br><strong>recursive</strong>:是否对子孙全部检索，默认True。<br><strong>string: &lt; &gt;… &lt; / &gt;</strong>:中字符串区域的检索字符串。      </p>
<p><strong>扩展方法</strong></p>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">&lt;&gt;.find()</td>
<td align="center">搜索且只返回一个结果，字符串类型，同.find_all()参数</td>
</tr>
<tr>
<td align="center">&lt;&gt;.find_parents()</td>
<td align="center">在先辈节点中搜索，返回列表类型，同.find_all()参数</td>
</tr>
<tr>
<td align="center">&lt;&gt;.find_parent()</td>
<td align="center">在先辈节点中返回一个结果，字符串类型，同.find()参数</td>
</tr>
<tr>
<td align="center">&lt;&gt;.find_next_siblings()</td>
<td align="center">在后续平行节点中搜索，返回列表类型，同.find_all()参数</td>
</tr>
<tr>
<td align="center">&lt;&gt;.find_ next sibling()</td>
<td align="center">在后续平行节点中返回一个结果，字符串类型,同.find()参数</td>
</tr>
<tr>
<td align="center">&lt;&gt;.find_previous_siblings()</td>
<td align="center">在前序平行节点中搜索，返回列表类型，同.find_all()参数</td>
</tr>
<tr>
<td align="center">&lt;&gt;.find_previous_sibling()</td>
<td align="center">在前序平行节点中返回一个结果，字符串类型，同.find()参数</td>
</tr>
</tbody></table>
</div><hr></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://i.loli.net/2020/05/12/jFsUgX9TBbnQu2o.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2020 By LyC</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>